{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:21.598922Z",
     "start_time": "2018-07-24T07:02:19.234769Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "\n",
    "INPUT_DIR = \"/Users/ashwins/Scripts/chatbot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:21.624898Z",
     "start_time": "2018-07-24T07:02:21.620942Z"
    }
   },
   "outputs": [],
   "source": [
    "EOS_TAG = \" EOS \"\n",
    "PAD_TAG = \" PAD \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:24.273468Z",
     "start_time": "2018-07-24T07:02:21.652132Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>l_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOS They do not! EOS</td>\n",
       "      <td>L1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EOS They do to! EOS</td>\n",
       "      <td>L1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EOS I hope so. EOS</td>\n",
       "      <td>L985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EOS She okay? EOS</td>\n",
       "      <td>L984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EOS Let's go. EOS</td>\n",
       "      <td>L925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EOS Wow EOS</td>\n",
       "      <td>L924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EOS Okay -- you're gonna need to learn how to...</td>\n",
       "      <td>L872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EOS No EOS</td>\n",
       "      <td>L871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EOS I'm kidding.  You know how sometimes you ...</td>\n",
       "      <td>L870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EOS Like my fear of wearing pastels? EOS</td>\n",
       "      <td>L869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EOS The \"real you\". EOS</td>\n",
       "      <td>L868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EOS What good stuff? EOS</td>\n",
       "      <td>L867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EOS I figured you'd get to the good stuff eve...</td>\n",
       "      <td>L866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EOS Thank God!  If I had to hear one more sto...</td>\n",
       "      <td>L865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EOS Me.  This endless ...blonde babble. I'm l...</td>\n",
       "      <td>L864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EOS What crap? EOS</td>\n",
       "      <td>L863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EOS do you listen to this crap? EOS</td>\n",
       "      <td>L862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EOS No... EOS</td>\n",
       "      <td>L861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EOS Then Guillermo says, \"If you go any light...</td>\n",
       "      <td>L860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EOS You always been this selfish? EOS</td>\n",
       "      <td>L699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EOS But EOS</td>\n",
       "      <td>L698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EOS Then that's all you had to say. EOS</td>\n",
       "      <td>L697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EOS Well, no... EOS</td>\n",
       "      <td>L696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EOS You never wanted to go out with 'me, did ...</td>\n",
       "      <td>L695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EOS I was? EOS</td>\n",
       "      <td>L694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EOS I looked for you back at the party, but y...</td>\n",
       "      <td>L693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EOS Tons EOS</td>\n",
       "      <td>L663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EOS Have fun tonight? EOS</td>\n",
       "      <td>L662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EOS I believe we share an art instructor EOS</td>\n",
       "      <td>L578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EOS You know Chastity? EOS</td>\n",
       "      <td>L577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304683</th>\n",
       "      <td>EOS The only reports of enemy activity have c...</td>\n",
       "      <td>L666460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304684</th>\n",
       "      <td>EOS Our runners bare his dispatches, do they ...</td>\n",
       "      <td>L666385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304685</th>\n",
       "      <td>EOS Er, called Noggs, Sir Actual name is Norr...</td>\n",
       "      <td>L666384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304686</th>\n",
       "      <td>EOS What's that strange name the newspaper ch...</td>\n",
       "      <td>L666383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304687</th>\n",
       "      <td>EOS But will they make good use of them? EOS</td>\n",
       "      <td>L666252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304688</th>\n",
       "      <td>EOS Yes. I see you've issued each of them wit...</td>\n",
       "      <td>L666251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304689</th>\n",
       "      <td>EOS Right.  Bombardier, to me please. EOS</td>\n",
       "      <td>L666502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304690</th>\n",
       "      <td>EOS Well, fed or hungry, Pulleine wants them ...</td>\n",
       "      <td>L666501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304691</th>\n",
       "      <td>EOS Well, my horses are feeding, as you may o...</td>\n",
       "      <td>L666500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304692</th>\n",
       "      <td>EOS How quickly can you move your artillery f...</td>\n",
       "      <td>L666499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304693</th>\n",
       "      <td>EOS Yes. EOS</td>\n",
       "      <td>L666498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304694</th>\n",
       "      <td>EOS Stuart? EOS</td>\n",
       "      <td>L666497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304695</th>\n",
       "      <td>EOS Keep steady. You're the best shots of the...</td>\n",
       "      <td>L666576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304696</th>\n",
       "      <td>EOS Choose your targets men. That's right Wat...</td>\n",
       "      <td>L666575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304697</th>\n",
       "      <td>EOS ft could be you flatter yourself CoghilL ...</td>\n",
       "      <td>L666327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304698</th>\n",
       "      <td>EOS Well that one. The one who keeps looking ...</td>\n",
       "      <td>L666326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304699</th>\n",
       "      <td>EOS Which one? EOS</td>\n",
       "      <td>L666325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304700</th>\n",
       "      <td>EOS Do you think she might be interested in  ...</td>\n",
       "      <td>L666324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304701</th>\n",
       "      <td>EOS Well that's typical of Her Majesty's army...</td>\n",
       "      <td>L666264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304702</th>\n",
       "      <td>EOS Um. There are rumours that my Lord Chelms...</td>\n",
       "      <td>L666263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304703</th>\n",
       "      <td>EOS Lighting COGHILL' 5 cigar: Our good Colon...</td>\n",
       "      <td>L666262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304704</th>\n",
       "      <td>EOS So far only their scouts. But we have had...</td>\n",
       "      <td>L666522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304705</th>\n",
       "      <td>EOS And I assure you, you do not In fact I'd ...</td>\n",
       "      <td>L666521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304706</th>\n",
       "      <td>EOS Well I assure you, Sir, I have no desire ...</td>\n",
       "      <td>L666520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304707</th>\n",
       "      <td>EOS I think Chelmsford wants a good man on th...</td>\n",
       "      <td>L666372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304708</th>\n",
       "      <td>EOS Lord Chelmsford seems to want me to stay ...</td>\n",
       "      <td>L666371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304709</th>\n",
       "      <td>EOS I'm to take the Sikali with the main colu...</td>\n",
       "      <td>L666370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304710</th>\n",
       "      <td>EOS Your orders, Mr Vereker? EOS</td>\n",
       "      <td>L666369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304711</th>\n",
       "      <td>EOS Good ones, yes, Mr Vereker. Gentlemen who...</td>\n",
       "      <td>L666257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304712</th>\n",
       "      <td>EOS Colonel Durnford... William Vereker. I he...</td>\n",
       "      <td>L666256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304713 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 dialogue     l_no\n",
       "0                                   EOS They do not! EOS     L1045\n",
       "1                                    EOS They do to! EOS     L1044\n",
       "2                                     EOS I hope so. EOS      L985\n",
       "3                                      EOS She okay? EOS      L984\n",
       "4                                      EOS Let's go. EOS      L925\n",
       "5                                            EOS Wow EOS      L924\n",
       "6        EOS Okay -- you're gonna need to learn how to...     L872\n",
       "7                                             EOS No EOS      L871\n",
       "8        EOS I'm kidding.  You know how sometimes you ...     L870\n",
       "9               EOS Like my fear of wearing pastels? EOS      L869\n",
       "10                               EOS The \"real you\". EOS      L868\n",
       "11                              EOS What good stuff? EOS      L867\n",
       "12       EOS I figured you'd get to the good stuff eve...     L866\n",
       "13       EOS Thank God!  If I had to hear one more sto...     L865\n",
       "14       EOS Me.  This endless ...blonde babble. I'm l...     L864\n",
       "15                                    EOS What crap? EOS      L863\n",
       "16                   EOS do you listen to this crap? EOS      L862\n",
       "17                                         EOS No... EOS      L861\n",
       "18       EOS Then Guillermo says, \"If you go any light...     L860\n",
       "19                 EOS You always been this selfish? EOS      L699\n",
       "20                                           EOS But EOS      L698\n",
       "21               EOS Then that's all you had to say. EOS      L697\n",
       "22                                   EOS Well, no... EOS      L696\n",
       "23       EOS You never wanted to go out with 'me, did ...     L695\n",
       "24                                        EOS I was? EOS      L694\n",
       "25       EOS I looked for you back at the party, but y...     L693\n",
       "26                                          EOS Tons EOS      L663\n",
       "27                             EOS Have fun tonight? EOS      L662\n",
       "28          EOS I believe we share an art instructor EOS      L578\n",
       "29                            EOS You know Chastity? EOS      L577\n",
       "...                                                   ...      ...\n",
       "304683   EOS The only reports of enemy activity have c...  L666460\n",
       "304684   EOS Our runners bare his dispatches, do they ...  L666385\n",
       "304685   EOS Er, called Noggs, Sir Actual name is Norr...  L666384\n",
       "304686   EOS What's that strange name the newspaper ch...  L666383\n",
       "304687      EOS But will they make good use of them? EOS   L666252\n",
       "304688   EOS Yes. I see you've issued each of them wit...  L666251\n",
       "304689         EOS Right.  Bombardier, to me please. EOS   L666502\n",
       "304690   EOS Well, fed or hungry, Pulleine wants them ...  L666501\n",
       "304691   EOS Well, my horses are feeding, as you may o...  L666500\n",
       "304692   EOS How quickly can you move your artillery f...  L666499\n",
       "304693                                      EOS Yes. EOS   L666498\n",
       "304694                                   EOS Stuart? EOS   L666497\n",
       "304695   EOS Keep steady. You're the best shots of the...  L666576\n",
       "304696   EOS Choose your targets men. That's right Wat...  L666575\n",
       "304697   EOS ft could be you flatter yourself CoghilL ...  L666327\n",
       "304698   EOS Well that one. The one who keeps looking ...  L666326\n",
       "304699                                EOS Which one? EOS   L666325\n",
       "304700   EOS Do you think she might be interested in  ...  L666324\n",
       "304701   EOS Well that's typical of Her Majesty's army...  L666264\n",
       "304702   EOS Um. There are rumours that my Lord Chelms...  L666263\n",
       "304703   EOS Lighting COGHILL' 5 cigar: Our good Colon...  L666262\n",
       "304704   EOS So far only their scouts. But we have had...  L666522\n",
       "304705   EOS And I assure you, you do not In fact I'd ...  L666521\n",
       "304706   EOS Well I assure you, Sir, I have no desire ...  L666520\n",
       "304707   EOS I think Chelmsford wants a good man on th...  L666372\n",
       "304708   EOS Lord Chelmsford seems to want me to stay ...  L666371\n",
       "304709   EOS I'm to take the Sikali with the main colu...  L666370\n",
       "304710                  EOS Your orders, Mr Vereker? EOS   L666369\n",
       "304711   EOS Good ones, yes, Mr Vereker. Gentlemen who...  L666257\n",
       "304712   EOS Colonel Durnford... William Vereker. I he...  L666256\n",
       "\n",
       "[304713 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dialogue = []\n",
    "l_no = []\n",
    "with open (INPUT_DIR + 'movie_data/movie_lines.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "#         print(l)\n",
    "#         print(json.dumps(l))\n",
    "        l = l.decode('windows-1252')\n",
    "        dialogue.append(EOS_TAG + l.split('+++$+++')[-1].lstrip().rstrip() + EOS_TAG)\n",
    "        l_no.append(l.split('+++$+++')[0].lstrip().rstrip())\n",
    "\n",
    "df_lines = pd.DataFrame({'dialogue': dialogue, 'l_no': l_no})\n",
    "display(df_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:25.378663Z",
     "start_time": "2018-07-24T07:02:24.883750Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L199</td>\n",
       "      <td>L198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L208</td>\n",
       "      <td>L207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L277</td>\n",
       "      <td>L276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L281</td>\n",
       "      <td>L280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L364</td>\n",
       "      <td>L363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L366</td>\n",
       "      <td>L365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L368</td>\n",
       "      <td>L367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L576</td>\n",
       "      <td>L575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L578</td>\n",
       "      <td>L577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L663</td>\n",
       "      <td>L662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>L861</td>\n",
       "      <td>L860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L925</td>\n",
       "      <td>L924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L985</td>\n",
       "      <td>L984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>L1045</td>\n",
       "      <td>L1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>L580</td>\n",
       "      <td>L579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>L660</td>\n",
       "      <td>L659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>L953</td>\n",
       "      <td>L952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>L395</td>\n",
       "      <td>L394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>L397</td>\n",
       "      <td>L396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>L593</td>\n",
       "      <td>L592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>L760</td>\n",
       "      <td>L759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>L165</td>\n",
       "      <td>L164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>L320</td>\n",
       "      <td>L319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>L530</td>\n",
       "      <td>L529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>L543</td>\n",
       "      <td>L542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>L602</td>\n",
       "      <td>L601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>L656</td>\n",
       "      <td>L655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>L983</td>\n",
       "      <td>L982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>L1022</td>\n",
       "      <td>L1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>L1052</td>\n",
       "      <td>L1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38061</th>\n",
       "      <td>L665841</td>\n",
       "      <td>L665840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38062</th>\n",
       "      <td>L665862</td>\n",
       "      <td>L665861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38063</th>\n",
       "      <td>L665874</td>\n",
       "      <td>L665873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38064</th>\n",
       "      <td>L665905</td>\n",
       "      <td>L665904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38065</th>\n",
       "      <td>L665958</td>\n",
       "      <td>L665957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38066</th>\n",
       "      <td>L666030</td>\n",
       "      <td>L666029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38067</th>\n",
       "      <td>L666042</td>\n",
       "      <td>L666041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38068</th>\n",
       "      <td>L666211</td>\n",
       "      <td>L666210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38069</th>\n",
       "      <td>L666215</td>\n",
       "      <td>L666214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38070</th>\n",
       "      <td>L666222</td>\n",
       "      <td>L666221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38071</th>\n",
       "      <td>L665652</td>\n",
       "      <td>L665651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38072</th>\n",
       "      <td>L665886</td>\n",
       "      <td>L665885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38073</th>\n",
       "      <td>L665901</td>\n",
       "      <td>L665900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38074</th>\n",
       "      <td>L666150</td>\n",
       "      <td>L666149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38075</th>\n",
       "      <td>L666159</td>\n",
       "      <td>L666158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38076</th>\n",
       "      <td>L666161</td>\n",
       "      <td>L666160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38077</th>\n",
       "      <td>L666167</td>\n",
       "      <td>L666166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38078</th>\n",
       "      <td>L666169</td>\n",
       "      <td>L666168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38079</th>\n",
       "      <td>L665993</td>\n",
       "      <td>L665992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38080</th>\n",
       "      <td>L666463</td>\n",
       "      <td>L666462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38081</th>\n",
       "      <td>L666250</td>\n",
       "      <td>L666249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38082</th>\n",
       "      <td>L666358</td>\n",
       "      <td>L666357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38083</th>\n",
       "      <td>L666484</td>\n",
       "      <td>L666483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38084</th>\n",
       "      <td>L666488</td>\n",
       "      <td>L666487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38085</th>\n",
       "      <td>L666252</td>\n",
       "      <td>L666251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38086</th>\n",
       "      <td>L666461</td>\n",
       "      <td>L666460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38087</th>\n",
       "      <td>L666486</td>\n",
       "      <td>L666485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38088</th>\n",
       "      <td>L666547</td>\n",
       "      <td>L666546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38089</th>\n",
       "      <td>L666576</td>\n",
       "      <td>L666575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38090</th>\n",
       "      <td>L666257</td>\n",
       "      <td>L666256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38091 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           end    start\n",
       "0         L199     L198\n",
       "1         L208     L207\n",
       "2         L277     L276\n",
       "3         L281     L280\n",
       "4         L364     L363\n",
       "5         L366     L365\n",
       "6         L368     L367\n",
       "7         L576     L575\n",
       "8         L578     L577\n",
       "9         L663     L662\n",
       "10        L861     L860\n",
       "11        L925     L924\n",
       "12        L985     L984\n",
       "13       L1045    L1044\n",
       "14        L580     L579\n",
       "15        L660     L659\n",
       "16        L953     L952\n",
       "17        L395     L394\n",
       "18        L397     L396\n",
       "19        L593     L592\n",
       "20        L760     L759\n",
       "21        L165     L164\n",
       "22        L320     L319\n",
       "23        L530     L529\n",
       "24        L543     L542\n",
       "25        L602     L601\n",
       "26        L656     L655\n",
       "27        L983     L982\n",
       "28       L1022    L1021\n",
       "29       L1052    L1051\n",
       "...        ...      ...\n",
       "38061  L665841  L665840\n",
       "38062  L665862  L665861\n",
       "38063  L665874  L665873\n",
       "38064  L665905  L665904\n",
       "38065  L665958  L665957\n",
       "38066  L666030  L666029\n",
       "38067  L666042  L666041\n",
       "38068  L666211  L666210\n",
       "38069  L666215  L666214\n",
       "38070  L666222  L666221\n",
       "38071  L665652  L665651\n",
       "38072  L665886  L665885\n",
       "38073  L665901  L665900\n",
       "38074  L666150  L666149\n",
       "38075  L666159  L666158\n",
       "38076  L666161  L666160\n",
       "38077  L666167  L666166\n",
       "38078  L666169  L666168\n",
       "38079  L665993  L665992\n",
       "38080  L666463  L666462\n",
       "38081  L666250  L666249\n",
       "38082  L666358  L666357\n",
       "38083  L666484  L666483\n",
       "38084  L666488  L666487\n",
       "38085  L666252  L666251\n",
       "38086  L666461  L666460\n",
       "38087  L666486  L666485\n",
       "38088  L666547  L666546\n",
       "38089  L666576  L666575\n",
       "38090  L666257  L666256\n",
       "\n",
       "[38091 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convo_start = []\n",
    "convo_end = []\n",
    "with open (INPUT_DIR + '/movie_data/movie_conversations.txt') as f:\n",
    "    for i, l in enumerate(f):\n",
    "#         if i==10:\n",
    "#             break\n",
    "#         print(type(l.split('+++$+++')[-1].lstrip().rstrip()))\n",
    "#         print(l.split('+++$+++')[-1].lstrip().rstrip())\n",
    "#         print(l.split('+++$+++')[-1].lstrip().rstrip().strip(\"[]\").split(','))\n",
    "        el = l.split('+++$+++')[-1].lstrip().rstrip().strip(\"[]\").split(',')\n",
    "        if len(el) == 2 :\n",
    "#             print(\"sdsd\")\n",
    "            for i, ele in enumerate(el):\n",
    "#                 print(ele)\n",
    "                ele = ele.lstrip().rstrip()\n",
    "                ele = ele.replace(\"'\", \"\")\n",
    "#                 print(ele)\n",
    "                el[i] = ele\n",
    "#             print(\"------------>\", el)\n",
    "            convo_start.append(el[0])\n",
    "            convo_end.append(el[1])\n",
    "#         print(json.loads(json.dumps(l.split('+++$+++')[-1].lstrip().rstrip()))[0])\n",
    "#         l_no.append(l.split('+++$+++')[0].lstrip().rstrip())\n",
    "df_convos = pd.DataFrame({'start': convo_start, 'end':convo_end})\n",
    "display(df_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:26.403268Z",
     "start_time": "2018-07-24T07:02:26.035096Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>l_no</th>\n",
       "      <th>l_no_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>EOS Did you change your hair? EOS</td>\n",
       "      <td>L49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>EOS No. EOS</td>\n",
       "      <td>L50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>EOS You might wanna think about it EOS</td>\n",
       "      <td>L51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>EOS I missed you. EOS</td>\n",
       "      <td>L59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>EOS It says here you exposed yourself to a gr...</td>\n",
       "      <td>L60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              dialogue l_no  l_no_int\n",
       "86                  EOS Did you change your hair? EOS   L49        49\n",
       "85                                        EOS No. EOS   L50        50\n",
       "84             EOS You might wanna think about it EOS   L51        51\n",
       "648                             EOS I missed you. EOS   L59        59\n",
       "647   EOS It says here you exposed yourself to a gr...  L60        60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lines['l_no_int'] = df_lines['l_no'].str[1:].astype(int)\n",
    "df_lines.head()\n",
    "# \n",
    "df_lines.sort_values(by =['l_no_int'], ascending=True, inplace=True)\n",
    "df_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:27.302248Z",
     "start_time": "2018-07-24T07:02:27.085104Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(INPUT_DIR + 'movie_data/movie_conversations_temp.txt', 'w') as f:\n",
    "#     for i, row in df_lines.iterrows():\n",
    "    f.writelines(df_lines['dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:28.089739Z",
     "start_time": "2018-07-24T07:02:27.932969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19889018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  EOS Did you change your hair? EOS  EOS No. EOS  EOS You might wanna think about it EOS  EOS I missed you. EOS  EOS It says here you exposed yourself to a group of freshmen girls. EOS  EOS It was a b'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str2=''\n",
    "with open(INPUT_DIR + 'movie_data/movie_conversations_temp.txt', 'r') as f:\n",
    "    corpus_text_2 = f.readlines()\n",
    "#     print(corpus_text_2[0])\n",
    "    for c in corpus_text_2:\n",
    "        str2 = ' '.join([str2, c])\n",
    "\n",
    "print(len(str2))\n",
    "str2[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:43.531763Z",
     "start_time": "2018-07-24T07:02:29.401806Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, TimeDistributed\n",
    "import pickle\n",
    "# import nltk\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "# from keras.utils import preprocessing\n",
    "# from model.textGenModel import TextGenModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:44.650138Z",
     "start_time": "2018-07-24T07:02:44.642307Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_words_mappings(tokenized_sentences, vocabulary_size):\n",
    "    # Using NLTK\n",
    "    #frequence = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "    #vocab = frequence.most_common(vocabulary_size)\n",
    "\n",
    "    # Using basic counter\n",
    "    counter = collections.Counter(itertools.chain(*tokenized_sentences))\n",
    "    vocab = counter.most_common(vocabulary_size)\n",
    "    index_to_word = [x[0] for x in vocab]\n",
    "    # Add padding for index 0\n",
    "    index_to_word.insert(0, PADDING_TOKEN)\n",
    "    index_to_word.insert(1, START_TOKEN)\n",
    "    # Append unknown token (with index = vocabulary size + 1)\n",
    "    index_to_word.append(UNKNOWN_TOKEN)\n",
    "    word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    "    \n",
    "    return index_to_word, word_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:02:45.739114Z",
     "start_time": "2018-07-24T07:02:45.733150Z"
    }
   },
   "outputs": [],
   "source": [
    "# constant token and params for our models\n",
    "START_TOKEN = \"EOS\"\n",
    "END_TOKEN = \"EOS\"\n",
    "UNKNOWN_TOKEN = \"UNK\"\n",
    "PADDING_TOKEN = \"PAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:20:44.445385Z",
     "start_time": "2018-07-24T07:04:38.283099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tokenized excerpt: ['EOS', 'No', '.', 'EOS', ' ', 'EOS', 'You', 'might', 'wanna', 'think']\n"
     ]
    }
   ],
   "source": [
    "# vocabulary_size = 22285\n",
    "sent_max_len = 20\n",
    "\n",
    "# hidden_size = 512\n",
    "hidden_size = 128\n",
    "embedding_size = 128\n",
    "batch_size = 64\n",
    "stateful = False\n",
    "\n",
    "corpus_text3 = str2\n",
    "corpus_tokens_tmp=[]\n",
    "for i in range(0, 16000000, 100000):\n",
    "    tmp_corpus = [token.orth_ for token in nlp(corpus_text3[i:i + 100000])]\n",
    "    corpus_tokens_tmp = corpus_tokens_tmp + tmp_corpus\n",
    "print('Example tokenized excerpt: {}'.format(corpus_tokens_tmp[10:20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:26:07.233449Z",
     "start_time": "2018-07-24T07:26:06.005123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4172374\n",
      "Vocabulary size = 50003\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_tokens_tmp))\n",
    "vocabulary_size = 50000\n",
    "index_to_word, word_to_index = get_words_mappings(\n",
    "                                        [corpus_tokens_tmp], #cause a list of sentences is expected\n",
    "                                        vocabulary_size)\n",
    "vocabulary_size = len(index_to_word)\n",
    "print(\"Vocabulary size = \" + str(vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:26:09.818895Z",
     "start_time": "2018-07-24T07:26:09.346324Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            dialogue  l_no  l_no_int   end  \\\n",
      "0                         EOS That I'm used to. EOS    L77        77   L78   \n",
      "1                              EOS Tempestuous? EOS   L108       108  L109   \n",
      "2   EOS Mandella, eat.  Starving yourself is a ve...  L129       129  L130   \n",
      "3                              EOS What's this? EOS   L131       131  L132   \n",
      "4   EOS I realize that the men of this fine insti...  L133       133  L134   \n",
      "\n",
      "  start  \n",
      "0   L77  \n",
      "1  L108  \n",
      "2  L129  \n",
      "3  L131  \n",
      "4  L133  \n",
      "                                          dialogue_x l_no_x  l_no_int_x   end  \\\n",
      "0                         EOS That I'm used to. EOS     L77          77   L78   \n",
      "1                              EOS Tempestuous? EOS    L108         108  L109   \n",
      "2   EOS Mandella, eat.  Starving yourself is a ve...   L129         129  L130   \n",
      "3                              EOS What's this? EOS    L131         131  L132   \n",
      "4   EOS I realize that the men of this fine insti...   L133         133  L134   \n",
      "\n",
      "  start                                         dialogue_y l_no_y  l_no_int_y  \n",
      "0   L77   EOS Yeah, but these guys have never seen a ho...    L78          78  \n",
      "1  L108   EOS No ... I believe \"heinous bitch\" is the t...   L109         109  \n",
      "2  L129                            EOS Just a little. EOS    L130         130  \n",
      "3  L131                        EOS An attempted slit. EOS    L132         132  \n",
      "4  L133   EOS But imagine the things he'd say during se...   L134         134  \n"
     ]
    }
   ],
   "source": [
    "df_train_data = pd.merge(df_lines, df_convos, left_on=['l_no'], right_on=['start'])\n",
    "print(df_train_data.head())\n",
    "df_train_data = pd.merge(df_train_data, df_lines, left_on=['end'], right_on=['l_no'])\n",
    "# df_train_data['end'] = df_train_data[df_convos.loc]\n",
    "print(df_train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:26:12.103629Z",
     "start_time": "2018-07-24T07:26:11.998194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38091, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_x</th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "      <th>dialogue_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOS That I'm used to. EOS</td>\n",
       "      <td>L78</td>\n",
       "      <td>L77</td>\n",
       "      <td>EOS Yeah, but these guys have never seen a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EOS Tempestuous? EOS</td>\n",
       "      <td>L109</td>\n",
       "      <td>L108</td>\n",
       "      <td>EOS No ... I believe \"heinous bitch\" is the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EOS Mandella, eat.  Starving yourself is a ve...</td>\n",
       "      <td>L130</td>\n",
       "      <td>L129</td>\n",
       "      <td>EOS Just a little. EOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EOS What's this? EOS</td>\n",
       "      <td>L132</td>\n",
       "      <td>L131</td>\n",
       "      <td>EOS An attempted slit. EOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EOS I realize that the men of this fine insti...</td>\n",
       "      <td>L134</td>\n",
       "      <td>L133</td>\n",
       "      <td>EOS But imagine the things he'd say during se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          dialogue_x   end start  \\\n",
       "0                         EOS That I'm used to. EOS    L78   L77   \n",
       "1                              EOS Tempestuous? EOS   L109  L108   \n",
       "2   EOS Mandella, eat.  Starving yourself is a ve...  L130  L129   \n",
       "3                              EOS What's this? EOS   L132  L131   \n",
       "4   EOS I realize that the men of this fine insti...  L134  L133   \n",
       "\n",
       "                                          dialogue_y  \n",
       "0   EOS Yeah, but these guys have never seen a ho...  \n",
       "1   EOS No ... I believe \"heinous bitch\" is the t...  \n",
       "2                            EOS Just a little. EOS   \n",
       "3                        EOS An attempted slit. EOS   \n",
       "4   EOS But imagine the things he'd say during se...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_data.drop(columns=['l_no_int_x', 'l_no_x', 'l_no_int_y', 'l_no_y'], inplace=True)\n",
    "print(df_train_data.shape)\n",
    "df_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:26:14.566652Z",
     "start_time": "2018-07-24T07:26:14.338594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>input</th>\n",
       "      <th>end</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L77</td>\n",
       "      <td>EOS That I'm used to. EOS</td>\n",
       "      <td>L78</td>\n",
       "      <td>EOS Yeah, but these guys have never seen a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L108</td>\n",
       "      <td>EOS Tempestuous? EOS</td>\n",
       "      <td>L109</td>\n",
       "      <td>EOS No ... I believe \"heinous bitch\" is the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L129</td>\n",
       "      <td>EOS Mandella, eat.  Starving yourself is a ve...</td>\n",
       "      <td>L130</td>\n",
       "      <td>EOS Just a little. EOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L131</td>\n",
       "      <td>EOS What's this? EOS</td>\n",
       "      <td>L132</td>\n",
       "      <td>EOS An attempted slit. EOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L133</td>\n",
       "      <td>EOS I realize that the men of this fine insti...</td>\n",
       "      <td>L134</td>\n",
       "      <td>EOS But imagine the things he'd say during se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start                                              input   end  \\\n",
       "0   L77                         EOS That I'm used to. EOS    L78   \n",
       "1  L108                              EOS Tempestuous? EOS   L109   \n",
       "2  L129   EOS Mandella, eat.  Starving yourself is a ve...  L130   \n",
       "3  L131                              EOS What's this? EOS   L132   \n",
       "4  L133   EOS I realize that the men of this fine insti...  L134   \n",
       "\n",
       "                                              output  \n",
       "0   EOS Yeah, but these guys have never seen a ho...  \n",
       "1   EOS No ... I believe \"heinous bitch\" is the t...  \n",
       "2                            EOS Just a little. EOS   \n",
       "3                        EOS An attempted slit. EOS   \n",
       "4   EOS But imagine the things he'd say during se...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df_train_data.columns\n",
    "cols = [cols[2], cols[0], cols[1], cols[3]]\n",
    "df_train_data = df_train_data[cols]\n",
    "df_train_data.rename(index=str, columns = {'dialogue_x' : 'input', 'dialogue_y' : 'output'}, inplace=True)\n",
    "df_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:26:16.800910Z",
     "start_time": "2018-07-24T07:26:16.795323Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "df_train_inputs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:27:12.351735Z",
     "start_time": "2018-07-24T07:26:19.187000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38091, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L78</td>\n",
       "      <td>[2, 65, 6, 2096, 332, 10, 2]</td>\n",
       "      <td>[2, 99, 74, 210, 296, 28, 123, 311, 12, 1214, ...</td>\n",
       "      <td>L77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L109</td>\n",
       "      <td>[2, 50002, 2]</td>\n",
       "      <td>[2, 58, 6, 216, 18960, 702, 24, 9, 2691, 332, ...</td>\n",
       "      <td>L108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L130</td>\n",
       "      <td>[2, 32300, 515, 26625, 260, 24, 12, 159, 1245,...</td>\n",
       "      <td>[2, 166, 12, 136, 2]</td>\n",
       "      <td>L129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L132</td>\n",
       "      <td>[2, 31, 2644, 33, 2]</td>\n",
       "      <td>[2, 675, 8438, 7671, 2]</td>\n",
       "      <td>L131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L134</td>\n",
       "      <td>[2, 6, 959, 21, 9, 349, 18, 33, 315, 5161, 45,...</td>\n",
       "      <td>[2, 82, 1022, 9, 192, 44, 4371, 110, 1352, 673...</td>\n",
       "      <td>L133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    end                                              input  \\\n",
       "0   L78                       [2, 65, 6, 2096, 332, 10, 2]   \n",
       "1  L109                                      [2, 50002, 2]   \n",
       "2  L130  [2, 32300, 515, 26625, 260, 24, 12, 159, 1245,...   \n",
       "3  L132                               [2, 31, 2644, 33, 2]   \n",
       "4  L134  [2, 6, 959, 21, 9, 349, 18, 33, 315, 5161, 45,...   \n",
       "\n",
       "                                              output start  \n",
       "0  [2, 99, 74, 210, 296, 28, 123, 311, 12, 1214, ...   L77  \n",
       "1  [2, 58, 6, 216, 18960, 702, 24, 9, 2691, 332, ...  L108  \n",
       "2                               [2, 166, 12, 136, 2]  L129  \n",
       "3                            [2, 675, 8438, 7671, 2]  L131  \n",
       "4  [2, 82, 1022, 9, 192, 44, 4371, 110, 1352, 673...  L133  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = []\n",
    "for i, row in df_train_data.iterrows() :\n",
    "    train_inputs = []\n",
    "    train_outputs = []\n",
    "    # convert tokens to indexes (and replacing unknown words)\n",
    "#     print([w for w in row[1]])\n",
    "#     print(type(row[1]))\n",
    "    train_inputs = [word_to_index.get(w, word_to_index[UNKNOWN_TOKEN]) \n",
    "              for w in re.sub(\"[^\\w]\", \" \", row[1]).split()]\n",
    "    train_outputs = [word_to_index.get(w, word_to_index[UNKNOWN_TOKEN]) \n",
    "              for w in re.sub(\"[^\\w]\", \" \", row[3]).split()]\n",
    "    \n",
    "#     print(\"start : \", row[1])\n",
    "#     print(train_inputs)\n",
    "#     print(\"end :\", row[3])\n",
    "#     print(train_outputs)\n",
    "    train_series = pd.DataFrame(data= {'start' : row[0], 'input' : [train_inputs], 'end' : row[2], 'output' : [train_outputs]})\n",
    "    train_list.append(train_series)\n",
    "\n",
    "df_train_inputs = pd.concat(train_list, ignore_index=True)\n",
    "print(df_train_inputs.shape)\n",
    "assert df_train_data.shape == df_train_inputs.shape\n",
    "df_train_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T09:02:48.742413Z",
     "start_time": "2018-07-24T09:02:47.168115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38080, 20)\n",
      "[[    2    65     6  2096   332    10     2     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    2 50002     2     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    2 32300   515 26625   260    24    12   159  1245   125    10   399\n",
      "      2     0     0     0     0     0     0     0]\n",
      " [    2    31  2644    33     2     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    2     6   959    21     9   349    18    33   315  5161    45 12634\n",
      "  10169    74  1002   260    80     7    69    34]]\n"
     ]
    }
   ],
   "source": [
    "length = len(sorted(df_train_inputs['input'],key=len, reverse=True)[0])\n",
    "max_sent_len = 20\n",
    "encoder_input_data=np.array([xi+[0]*(length-len(xi)) for xi in df_train_inputs['input']])\n",
    "encoder_input_data = encoder_input_data[:38080, :max_sent_len]\n",
    "print(encoder_input_data.shape)\n",
    "print(encoder_input_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T09:03:06.729583Z",
     "start_time": "2018-07-24T09:03:04.419198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38080, 20)\n",
      "[[    2    99    74   210   296    28   123   311    12  1214   101    51\n",
      "   5865   140    10 17478 21578     2     0     0]\n",
      " [    2    58     6   216 18960   702    24     9  2691   332   385  1357\n",
      "      2     0     0     0     0     0     0     0]\n",
      " [    2   166    12   136     2     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    2   675  8438  7671     2     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    2    82  1022     9   192    44  4371   110  1352   673     2     0\n",
      "      0     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "length = len(sorted(df_train_inputs['output'],key=len, reverse=True)[0])\n",
    "# length = 20\n",
    "decoder_input_data=np.array([xi+[0]*(length-len(xi)) for xi in df_train_inputs['output']])\n",
    "decoder_input_data = decoder_input_data[:38080, :max_sent_len]\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_input_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T09:03:28.573304Z",
     "start_time": "2018-07-24T09:03:22.291828Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38080, 20, 1)\n",
      "[[[   99]\n",
      "  [   74]\n",
      "  [  210]\n",
      "  [  296]\n",
      "  [   28]\n",
      "  [  123]\n",
      "  [  311]\n",
      "  [   12]\n",
      "  [ 1214]\n",
      "  [  101]\n",
      "  [   51]\n",
      "  [ 5865]\n",
      "  [  140]\n",
      "  [   10]\n",
      "  [17478]\n",
      "  [21578]\n",
      "  [    2]\n",
      "  [    2]\n",
      "  [    0]\n",
      "  [    0]]\n",
      "\n",
      " [[   58]\n",
      "  [    6]\n",
      "  [  216]\n",
      "  [18960]\n",
      "  [  702]\n",
      "  [   24]\n",
      "  [    9]\n",
      "  [ 2691]\n",
      "  [  332]\n",
      "  [  385]\n",
      "  [ 1357]\n",
      "  [    2]\n",
      "  [    2]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]]\n",
      "\n",
      " [[  166]\n",
      "  [   12]\n",
      "  [  136]\n",
      "  [    2]\n",
      "  [    2]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]]\n",
      "\n",
      " [[  675]\n",
      "  [ 8438]\n",
      "  [ 7671]\n",
      "  [    2]\n",
      "  [    2]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]]\n",
      "\n",
      " [[   82]\n",
      "  [ 1022]\n",
      "  [    9]\n",
      "  [  192]\n",
      "  [   44]\n",
      "  [ 4371]\n",
      "  [  110]\n",
      "  [ 1352]\n",
      "  [  673]\n",
      "  [    2]\n",
      "  [    2]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]\n",
      "  [    0]]]\n"
     ]
    }
   ],
   "source": [
    "length = len(sorted(df_train_inputs['output'],key=len, reverse=True)[0])\n",
    "# decoder_target_data = df_train_inputs.apply(lambda x: x[2][1:]+[x[2][0]], axis=1).values\n",
    "decoder_target_data=np.array([xi+[0]*(length-len(xi)) for xi in df_train_inputs.apply(lambda x: x[2][1:]+[x[2][0]], axis=1).values])\n",
    "decoder_target_data = decoder_target_data[:38080, :max_sent_len]\n",
    "decoder_target_data = np.expand_dims(decoder_target_data, -1)\n",
    "print(decoder_target_data.shape)\n",
    "print(decoder_target_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T09:03:40.562689Z",
     "start_time": "2018-07-24T09:03:40.554385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example train input sentence: [   2   65    6 2096  332   10    2    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "and related output = [[   99]\n",
      " [   74]\n",
      " [  210]\n",
      " [  296]\n",
      " [   28]\n",
      " [  123]\n",
      " [  311]\n",
      " [   12]\n",
      " [ 1214]\n",
      " [  101]\n",
      " [   51]\n",
      " [ 5865]\n",
      " [  140]\n",
      " [   10]\n",
      " [17478]\n",
      " [21578]\n",
      " [    2]\n",
      " [    2]\n",
      " [    0]\n",
      " [    0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example train input sentence: {}\".format(encoder_input_data[0]))\n",
    "print(\"and related output = {}\".format(decoder_target_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-22T04:40:50.836315Z",
     "start_time": "2018-07-22T04:40:45.771213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc inp :  (38091,)\n",
      "[list([2, 65, 6, 2077, 332, 10, 2]) list([2, 50002, 2])\n",
      " list([2, 28515, 515, 27014, 260, 24, 12, 159, 1240, 125, 10, 399, 2])\n",
      " list([2, 31, 2648, 33, 2])\n",
      " list([2, 6, 956, 21, 9, 349, 18, 33, 315, 5112, 45, 13159, 10250, 74, 998, 260, 80, 7, 69, 34, 42, 2124, 4131, 24, 1522, 9, 6764, 18, 1235, 8251, 18700, 19, 1657, 30167, 465, 794, 10577, 172, 327, 27883, 20, 4213, 9, 291, 18, 230, 117, 145, 159, 2574, 2624, 2])]\n",
      "dec inp :  (38091,)\n",
      "[list([2, 99, 74, 210, 296, 28, 123, 312, 12, 1216, 101, 51, 5853, 140, 10, 16863, 24021, 2])\n",
      " list([2, 58, 6, 216, 17824, 702, 24, 9, 2713, 332, 385, 1353, 2])\n",
      " list([2, 166, 12, 136, 2]) list([2, 675, 8353, 7660, 2])\n",
      " list([2, 82, 1022, 9, 192, 44, 4387, 110, 1355, 673, 2])]\n",
      "(38091,)\n",
      "[list([99, 74, 210, 296, 28, 123, 312, 12, 1216, 101, 51, 5853, 140, 10, 16863, 24021, 2, 2])\n",
      " list([58, 6, 216, 17824, 702, 24, 9, 2713, 332, 385, 1353, 2, 2])\n",
      " list([166, 12, 136, 2, 2]) list([675, 8353, 7660, 2, 2])\n",
      " list([82, 1022, 9, 192, 44, 4387, 110, 1355, 673, 2, 2])]\n",
      "enc inp shape (38091,)\n",
      "dec inp shape (38091,)\n",
      "dec target shape (38091, 1, 1)\n",
      "Example train input sentence: [2, 65, 6, 2077, 332, 10, 2]\n",
      "and related output = [[list([99, 74, 210, 296, 28, 123, 312, 12, 1216, 101, 51, 5853, 140, 10, 16863, 24021, 2, 2])]]\n"
     ]
    }
   ],
   "source": [
    "# encoder_input_data = np.array(df_train_inputs['input'])\n",
    "# decoder_input_data = np.array(df_train_inputs['output'])\n",
    "# print(\"enc inp : \", encoder_input_data.shape)\n",
    "# print(encoder_input_data[:5])\n",
    "# print(\"dec inp : \", decoder_input_data.shape)\n",
    "# print(decoder_input_data[:5])\n",
    "# # decoder_input_data = np.append(decoder_input_data, [train_data[0:sent_max_len]], axis=0)\n",
    "# decoder_target_data = df_train_inputs.apply(lambda x: x[2][1:]+[x[2][0]], axis=1).values\n",
    "# print(decoder_target_data.shape)\n",
    "# print(decoder_target_data[:5])\n",
    "# # decoder_target_data = np.array([train_data[i:i+sent_max_len] \n",
    "# #                     for i in range(sent_max_len+1, len(train_data)-remainer, sent_max_len)])\n",
    "# # decoder_target_data = np.append(decoder_target_data, [train_data[0:sent_max_len]], axis=0)\n",
    "# # temp = np_utils.to_categorical(decoder_target_data, vocabulary_size)\n",
    "# # print(temp.shape)\n",
    "# #X_train = np.expand_dims(X_train, -1)\n",
    "# decoder_target_data = np.reshape(decoder_target_data, (38091, -1, 1)) # needed cause out timedistributed layer\n",
    "\n",
    "# print(\"enc inp shape\", encoder_input_data.shape)\n",
    "# print(\"dec inp shape\", decoder_input_data.shape)\n",
    "# print(\"dec target shape\", decoder_target_data.shape)\n",
    "# # print(\"temp dec inp shape\", temp_decoder_input_data.shape)\n",
    "# print(\"Example train input sentence: {}\".format(encoder_input_data[0]))\n",
    "# print(\"and related output = {}\".format(decoder_target_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T14:29:26.825390Z",
     "start_time": "2018-07-21T14:29:23.815034Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3445827\n",
      "Vocabulary size = 50002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3445827"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(corpus_tokens_tmp))\n",
    "# vocabulary_size = 50000\n",
    "# index_to_word, word_to_index = get_words_mappings(\n",
    "#                                         [corpus_tokens_tmp], #cause a list of sentences is expected\n",
    "#                                         vocabulary_size)\n",
    "# vocabulary_size = len(index_to_word)\n",
    "# print(\"Vocabulary size = \" + str(vocabulary_size))\n",
    "\n",
    "# # convert tokens to indexes (and replacing unknown words)\n",
    "# train_data = [word_to_index.get(w, word_to_index[UNKNOWN_TOKEN]) \n",
    "#               for w in corpus_tokens_tmp]\n",
    "# train_data = train_data[:3825472]\n",
    "# len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-22T04:00:34.918859Z",
     "start_time": "2018-07-22T04:00:34.911437Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remainer = len(train_data)%sent_max_len\n",
    "# print(len(train_data)-remainer)\n",
    "# encoder_input_data = np.array([train_data[i:i+sent_max_len] \n",
    "#                     for i in range(0, len(train_data)-remainer, sent_max_len)])\n",
    "# decoder_input_data = np.array([train_data[i:i+sent_max_len] \n",
    "#                     for i in range(sent_max_len, len(train_data)-remainer, sent_max_len)])\n",
    "# # print(\"dec inp shape\", decoder_input_data.shape)\n",
    "# # print(len([train_data[0:sent_max_len]][0]))\n",
    "# decoder_input_data = np.append(decoder_input_data, [train_data[0:sent_max_len]], axis=0)\n",
    "\n",
    "# decoder_target_data = np.array([train_data[i:i+sent_max_len] \n",
    "#                     for i in range(sent_max_len+1, len(train_data)-remainer, sent_max_len)])\n",
    "# decoder_target_data = np.append(decoder_target_data, [train_data[0:sent_max_len]], axis=0)\n",
    "# # temp = np_utils.to_categorical(decoder_target_data, vocabulary_size)\n",
    "# # print(temp.shape)\n",
    "# #X_train = np.expand_dims(X_train, -1)\n",
    "# decoder_target_data = np.expand_dims(decoder_target_data, -1) # needed cause out timedistributed layer\n",
    "\n",
    "# print(\"enc inp shape\", encoder_input_data.shape)\n",
    "# print(\"dec inp shape\", decoder_input_data.shape)\n",
    "# print(\"dec target shape\", decoder_target_data.shape)\n",
    "# # print(\"temp dec inp shape\", temp_decoder_input_data.shape)\n",
    "# print(\"Example train input sentence: {}\".format(encoder_input_data[0]))\n",
    "# print(\"and related output = {}\".format(decoder_target_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:31:15.136077Z",
     "start_time": "2018-07-24T07:31:14.009758Z"
    }
   },
   "outputs": [],
   "source": [
    "# encoder_inputs = Input(shape=(None, ), name='enc_input')\n",
    "# -------------\n",
    "# To change\n",
    "encoder_inputs = Input(shape=(max_sent_len, ), name='enc_input')\n",
    "# -------------\n",
    "\n",
    "# shared_emb = Embedding(input_dim = vocabulary_size, output_dim = embedding_size, input_length=20, name='shared_emb')\n",
    "# -------------\n",
    "# To change\n",
    "shared_emb = Embedding(input_dim = vocabulary_size, output_dim = embedding_size, name='shared_emb', mask_zero=True)\n",
    "# -------------\n",
    "\n",
    "x = shared_emb(encoder_inputs)\n",
    "encoder = LSTM(max_sent_len, \n",
    "               return_state=True,\n",
    "               return_sequences=False,\n",
    "               name='enc_lstm'\n",
    "              )\n",
    "\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "encoder_outputs= encoder(x)\n",
    "encoder_states = [encoder_outputs[1], encoder_outputs[2]]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_sent_len,), name='dec_input')\n",
    "x = shared_emb(decoder_inputs)\n",
    "decoder = LSTM(max_sent_len, \n",
    "               return_sequences=True, \n",
    "               return_state = True,\n",
    "               name='dec_lstm'\n",
    "              )\n",
    "decoder_op, _, _ = decoder(x, initial_state=encoder_states)\n",
    "decoder_outputs = Dense(vocabulary_size, activation='softmax', name='dec_output')(decoder_op)\n",
    "# decoder_outputs = Dense(vocabulary_size, activation='softmax', name='dec_outputs')(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:31:20.220908Z",
     "start_time": "2018-07-24T07:31:20.210611Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "enc_input (InputLayer)       (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "shared_emb (Embedding)       (None, 20, 128)           6400384   \n",
      "_________________________________________________________________\n",
      "enc_lstm (LSTM)              [(None, 20), (None, 20),  11920     \n",
      "=================================================================\n",
      "Total params: 6,412,304\n",
      "Trainable params: 6,412,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(encoder_inputs, encoder_outputs)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:04:23.585733Z",
     "start_time": "2018-07-24T07:03:07.622Z"
    }
   },
   "outputs": [],
   "source": [
    "# decoder = Model(decoder_inputs, decoder_outputs)\n",
    "# decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:31:25.489552Z",
     "start_time": "2018-07-24T07:31:25.479049Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_input (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_emb (Embedding)          (None, 20, 128)      6400384     enc_input[0][0]                  \n",
      "                                                                 dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_lstm (LSTM)                 [(None, 20), (None,  11920       shared_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm (LSTM)                 [(None, 20, 20), (No 11920       shared_emb[1][0]                 \n",
      "                                                                 enc_lstm[0][1]                   \n",
      "                                                                 enc_lstm[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_output (Dense)              (None, 20, 50003)    1050063     dec_lstm[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,474,287\n",
      "Trainable params: 7,474,287\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "auto_encoder = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "auto_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T07:57:21.966299Z",
     "start_time": "2018-07-24T07:32:05.353767Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/keras/engine/network.py:888: UserWarning: Layer dec_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'enc_lstm/while/Exit_3:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'enc_lstm/while/Exit_4:0' shape=(?, 20) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "saved enc model\n",
      "saved enc weights\n",
      "saved weights\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 412s 103ms/step - loss: 10.2290 - val_loss: 8.7126\n",
      "saved model\n",
      "saved enc model\n",
      "saved enc weights\n",
      "saved weights\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 370s 92ms/step - loss: 7.3096 - val_loss: 6.1940\n",
      "saved model\n",
      "saved enc model\n",
      "saved enc weights\n",
      "saved weights\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 357s 89ms/step - loss: 5.6042 - val_loss: 4.9052\n",
      "saved model\n",
      "saved enc model\n",
      "saved enc weights\n",
      "saved weights\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 364s 91ms/step - loss: 4.9738 - val_loss: 4.7938\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "opt = Adam(lr=0.001)\n",
    "auto_encoder.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt)\n",
    "\n",
    "model_json = auto_encoder.to_json()\n",
    "with open(\"full_model_new_arch\", \"w\") as f:\n",
    "    f.write(json.dumps(json.loads((model_json))))\n",
    "\n",
    "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
    "# rather than sequences of integers like `decoder_input_data`!\n",
    "for i in range(4):\n",
    "    if i==3:\n",
    "        opt = Adam(lr=0.0001)\n",
    "        auto_encoder.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt)\n",
    "        \n",
    "#     if i==8:\n",
    "#         opt = Adam(lr=0.00001)\n",
    "#         model.compile(loss='sparse_categorical_crossentropy', optimizer=opt)\n",
    "        \n",
    "    model_name = 'full_model_new_epoch_' + str(i) + '.h5'\n",
    "    auto_encoder.save(model_name)\n",
    "    print('saved model')\n",
    "    \n",
    "    enc_name = 'enc_model_new_epoch_' + str(i) + '.h5'\n",
    "    encoder.save(enc_name)\n",
    "    print('saved enc model')\n",
    "    weights_path = ''.join(['enc_model_new_weights_', \n",
    "                        \"base_voc_{}_epoch_{}.hdf5\".format(vocabulary_size, \n",
    "                                                          i)])\n",
    "    encoder.save_weights(weights_path)\n",
    "    print('saved enc weights')\n",
    "    # export model weights\n",
    "    weights_path = ''.join(['full_model_new_weights_', \n",
    "                        \"base_voc_{}_epoch_{}.hdf5\".format(vocabulary_size, \n",
    "                                                          i)])\n",
    "    auto_encoder.save_weights(weights_path)\n",
    "    print('saved weights')\n",
    "    \n",
    "    auto_encoder.fit([encoder_input_data[:5000], decoder_input_data[:5000]], decoder_target_data[:5000], batch_size=batch_size, epochs=1, validation_split=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-22T13:14:50.627686Z",
     "start_time": "2018-07-22T13:14:47.889814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_input (InputLayer)          (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (InputLayer)          (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_emb (Embedding)          (None, 20, 128)      6400384     enc_input[0][0]                  \n",
      "                                                                 dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_lstm (LSTM)                 [(None, 20), (None,  11920       shared_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm (LSTM)                 [(None, 20, 20), (No 11920       shared_emb[1][0]                 \n",
      "                                                                 enc_lstm[0][1]                   \n",
      "                                                                 enc_lstm[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_output (Dense)              (None, 20, 50003)    1050063     dec_lstm[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,474,287\n",
      "Trainable params: 7,474,287\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_model_loaded = load_model('/Users/ashwins/Scripts/chatbot/full_model_new_epoch_3.h5')\n",
    "autoencoder_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T12:23:55.374629Z",
     "start_time": "2018-07-21T12:23:55.368054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x12150ba20>\n",
      "<keras.engine.input_layer.InputLayer object at 0x12150bb00>\n",
      "<keras.layers.embeddings.Embedding object at 0x1215030b8>\n",
      "<keras.layers.recurrent.LSTM object at 0x121503588>\n",
      "<keras.layers.recurrent.LSTM object at 0x1214904a8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x12150b8d0>\n"
     ]
    }
   ],
   "source": [
    "for l in autoencoder_model_loaded.layers:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T12:30:32.155158Z",
     "start_time": "2018-07-21T12:30:31.342371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.training.Model object at 0x1310c33c8>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model = load_model('/Users/ashwins/Scripts/chatbot/enc_model_new_epoch_3.h5')\n",
    "print(encoder_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T12:48:10.651046Z",
     "start_time": "2018-07-21T12:48:10.640711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "enc_input (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "shared_emb (Embedding)       (None, None, 128)         6400256   \n",
      "_________________________________________________________________\n",
      "enc_lstm (LSTM)              [(None, 20), (None, 20),  11920     \n",
      "=================================================================\n",
      "Total params: 6,412,176\n",
      "Trainable params: 6,412,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = autoencoder_model_loaded.get_layer('enc_input').output\n",
    "# enc_inputs = Input(shape=(None,), name='enc_input')\n",
    "# enc_emb = autoencoder_model_loaded.get_layer('shared_emb').get_output_at(0)\n",
    "enc_lstm = autoencoder_model_loaded.get_layer('enc_lstm').output\n",
    "\n",
    "encoder_model_loaded = Model(enc_inputs, enc_lstm)\n",
    "encoder_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T15:18:33.078043Z",
     "start_time": "2018-07-21T15:18:32.810885Z"
    }
   },
   "outputs": [],
   "source": [
    "dec_inp = autoencoder_model_loaded.get_layer('dec_input').output\n",
    "dec_emb = autoencoder_model_loaded.get_layer('shared_emb')(dec_inp)\n",
    "dec_lstm = autoencoder_model_loaded.get_layer('dec_lstm')(dec_emb)\n",
    "dec_output = autoencoder_model_loaded.get_layer('time_distributed_1')(dec_lstm)\n",
    "\n",
    "decoder_model_loaded = Model(dec_inp, dec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T14:31:15.684040Z",
     "start_time": "2018-07-21T14:31:15.630858Z"
    }
   },
   "outputs": [],
   "source": [
    "index_to_word_dict = dict([(i,w) for w,i in word_to_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T15:24:05.163244Z",
     "start_time": "2018-07-21T15:24:05.151248Z"
    }
   },
   "outputs": [],
   "source": [
    "UNKNOWN_TOKEN = \"UNKNOWN_TOKEN\"\n",
    "PAD_TOKEN = \"PADDING\"\n",
    "\n",
    "unknown_token_idx = word_to_index[UNKNOWN_TOKEN]\n",
    "pad_token_idx = word_to_index[PAD_TOKEN]\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    op, states_value0, states_value1 = encoder_model_loaded.predict(input_seq)\n",
    "    states_value = [states_value0, states_value1]\n",
    "    states_value = [np.argmax(states_value0), np.argmax(states_value1)]\n",
    "    print(index_to_word_dict.get(states_value[0]), index_to_word_dict.get(states_value[1]))\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "#     target_seq = np.empty(shape = (1), dtype=\"object\")\n",
    "    target_seq = []\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq.append(0)\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens = decoder_model_loaded.predict(\n",
    "            target_seq + states_value)\n",
    "        print(output_tokens.shape)\n",
    "        print(\"output tokens  : \",output_tokens)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[-1, -1, :])\n",
    "        \n",
    "        print(\"predicted word : \", index_to_word_dict.get(sampled_token_index,\"none\"))\n",
    "        sampled_word = index_to_word_dict[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        \n",
    "        if len(decoded_sentence) >= sent_max_len  : \n",
    "            stop_condition = True\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "#         if (sampled_char == '\\n' or\n",
    "#            len(decoded_sentence) > max_decoder_seq_length):\n",
    "#             stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "#         target_seq = np.empty(shape = (1), dtype=\"object\")\n",
    "        target_seq.append(sampled_token_index )\n",
    "\n",
    "        # Update states\n",
    "#         states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T15:24:06.506011Z",
     "start_time": "2018-07-21T15:24:06.451872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who at\n",
      "(3, 1, 50002)\n",
      "output tokens  :  [[[1.5712263e-05 3.9714509e-05 4.2413252e-05 ... 1.5632166e-05\n",
      "   1.8803472e-05 4.8559323e-05]]\n",
      "\n",
      " [[1.2478977e-06 3.0061946e-04 6.7590957e-04 ... 1.2548911e-06\n",
      "   6.7995129e-06 9.6291141e-04]]\n",
      "\n",
      " [[3.5689472e-06 6.8779023e-05 4.2234850e-04 ... 3.5430683e-06\n",
      "   1.1511301e-05 4.8780293e-04]]]\n",
      "predicted word :  the\n",
      "(4, 1, 50002)\n",
      "output tokens  :  [[[1.5712263e-05 3.9714509e-05 4.2413252e-05 ... 1.5632166e-05\n",
      "   1.8803472e-05 4.8559323e-05]]\n",
      "\n",
      " [[1.6842607e-05 2.1278142e-05 2.2884597e-05 ... 1.6829888e-05\n",
      "   1.9287223e-05 4.0822582e-05]]\n",
      "\n",
      " [[1.2478986e-06 3.0061940e-04 6.7590951e-04 ... 1.2548908e-06\n",
      "   6.7995147e-06 9.6291146e-04]]\n",
      "\n",
      " [[3.5689472e-06 6.8779023e-05 4.2234850e-04 ... 3.5430683e-06\n",
      "   1.1511301e-05 4.8780284e-04]]]\n",
      "predicted word :  the\n",
      "(5, 1, 50002)\n",
      "output tokens  :  [[[1.5712263e-05 3.9714509e-05 4.2413252e-05 ... 1.5632166e-05\n",
      "   1.8803472e-05 4.8559323e-05]]\n",
      "\n",
      " [[1.6842607e-05 2.1278142e-05 2.2884597e-05 ... 1.6829888e-05\n",
      "   1.9287223e-05 4.0822582e-05]]\n",
      "\n",
      " [[1.6842607e-05 2.1278142e-05 2.2884597e-05 ... 1.6829888e-05\n",
      "   1.9287223e-05 4.0822582e-05]]\n",
      "\n",
      " [[1.2478986e-06 3.0061940e-04 6.7590951e-04 ... 1.2548908e-06\n",
      "   6.7995147e-06 9.6291146e-04]]\n",
      "\n",
      " [[3.5689472e-06 6.8779023e-05 4.2234850e-04 ... 3.5430683e-06\n",
      "   1.1511301e-05 4.8780293e-04]]]\n",
      "predicted word :  the\n",
      "(6, 1, 50002)\n",
      "output tokens  :  [[[1.5712263e-05 3.9714509e-05 4.2413252e-05 ... 1.5632166e-05\n",
      "   1.8803472e-05 4.8559323e-05]]\n",
      "\n",
      " [[1.6842607e-05 2.1278142e-05 2.2884597e-05 ... 1.6829888e-05\n",
      "   1.9287223e-05 4.0822582e-05]]\n",
      "\n",
      " [[1.6842607e-05 2.1278142e-05 2.2884597e-05 ... 1.6829888e-05\n",
      "   1.9287223e-05 4.0822582e-05]]\n",
      "\n",
      " [[1.6842607e-05 2.1278142e-05 2.2884597e-05 ... 1.6829888e-05\n",
      "   1.9287223e-05 4.0822582e-05]]\n",
      "\n",
      " [[1.2478977e-06 3.0061946e-04 6.7590957e-04 ... 1.2548911e-06\n",
      "   6.7995129e-06 9.6291141e-04]]\n",
      "\n",
      " [[3.5689472e-06 6.8779023e-05 4.2234850e-04 ... 3.5430683e-06\n",
      "   1.1511301e-05 4.8780293e-04]]]\n",
      "predicted word :  the\n",
      "(7, 1, 50002)\n",
      "output tokens  :  [[[1.5712263e-05 3.9714509e-05 4.2413252e-05 ... 1.5632166e-05\n",
      "   1.8803472e-05 4.8559323e-05]]\n",
      "\n",
      " [[1.6842607e-05 2.1278142e-05 2.2884597e-05 ... 1.6829888e-05\n",
      "   1.9287223e-05 4.0822582e-05]]\n",
      "\n",
      " [[1.6842607e-05 2.1278142e-05 2.2884597e-05 ... 1.6829888e-05\n",
      "   1.9287223e-05 4.0822582e-05]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.6842607e-05 2.1278140e-05 2.2884595e-05 ... 1.6829888e-05\n",
      "   1.9287221e-05 4.0822579e-05]]\n",
      "\n",
      " [[1.2478977e-06 3.0061946e-04 6.7590957e-04 ... 1.2548911e-06\n",
      "   6.7995129e-06 9.6291141e-04]]\n",
      "\n",
      " [[3.5689472e-06 6.8779023e-05 4.2234850e-04 ... 3.5430683e-06\n",
      "   1.1511301e-05 4.8780293e-04]]]\n",
      "predicted word :  the\n",
      "output is :   the the the the the\n"
     ]
    }
   ],
   "source": [
    "test_str = \"Hey there?\"\n",
    "# text_eval =\"Did you change your hair?\"\n",
    "eval_data = [word_to_index.get(w, word_to_index[UNKNOWN_TOKEN]) \n",
    "              for w in test_str]\n",
    "op = decode_sequence(eval_data)\n",
    "print(\"output is : \", op)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "123px",
    "width": "162px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
