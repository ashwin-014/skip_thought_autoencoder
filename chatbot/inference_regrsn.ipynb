{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:30:57.951869Z",
     "start_time": "2018-08-12T10:30:44.121623Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, TimeDistributed\n",
    "import pickle\n",
    "# import nltk\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "# from keras.utils import preprocessing\n",
    "# from model.textGenModel import TextGenModel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "INPUT_DIR = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:30:58.101061Z",
     "start_time": "2018-08-12T10:30:57.955146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16841888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Did you change your hair?No.You might wanna think about itI missed you.It says here you exposed yourself to a group of freshmen girls.It was a bratwurst.  I was eating lunch.With the teeth of your zi'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str2=''\n",
    "with open(INPUT_DIR + 'movie_data/movie_conversations_temp.txt', 'r') as f:\n",
    "    corpus_text_2 = f.readlines()\n",
    "#     print(corpus_text_2[0])\n",
    "    for c in corpus_text_2:\n",
    "        str2 = ' '.join([str2, c])\n",
    "\n",
    "print(len(str2))\n",
    "str2[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:30:58.112151Z",
     "start_time": "2018-08-12T10:30:58.105876Z"
    }
   },
   "outputs": [],
   "source": [
    "# constant token and params for our models\n",
    "START_TOKEN = \"EOS\"\n",
    "END_TOKEN = \"EOS\"\n",
    "UNKNOWN_TOKEN = \"UNK\"\n",
    "PADDING_TOKEN = \"PAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:30:58.128145Z",
     "start_time": "2018-08-12T10:30:58.117081Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_words_mappings(tokenized_sentences, vocabulary_size):\n",
    "    # Using NLTK\n",
    "    #frequence = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "    #vocab = frequence.most_common(vocabulary_size)\n",
    "\n",
    "    # Using basic counter\n",
    "    counter = collections.Counter(itertools.chain(*tokenized_sentences))\n",
    "    vocab = counter.most_common(vocabulary_size)\n",
    "    index_to_word = [x[0] for x in vocab]\n",
    "    # Add padding for index 0\n",
    "    index_to_word.insert(0, START_TOKEN)\n",
    "    index_to_word.insert(1, PADDING_TOKEN)\n",
    "    # Append unknown token (with index = vocabulary size + 1)\n",
    "    index_to_word.append(UNKNOWN_TOKEN)\n",
    "    word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    "    \n",
    "    return index_to_word, word_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:30:58.163527Z",
     "start_time": "2018-08-12T10:30:58.146003Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "sent_max_len = 20\n",
    "\n",
    "# hidden_size = 512\n",
    "# hidden_size = 128\n",
    "# embedding_size = 128\n",
    "# batch_size = 64\n",
    "max_sent_len = 20\n",
    "embedding_size = 32\n",
    "stateful = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:30:58.185911Z",
     "start_time": "2018-08-12T10:30:58.174936Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# corpus_text3 = str2\n",
    "# corpus_tokens_tmp=[]\n",
    "# for i in range(0, 16000000, 100000):\n",
    "#     print(i)\n",
    "#     tmp_corpus = [token.orth_ for token in nlp(corpus_text3[i:i + 100000])]\n",
    "#     corpus_tokens_tmp = corpus_tokens_tmp + tmp_corpus\n",
    "# print('Example tokenized excerpt: {}'.format(corpus_tokens_tmp[10:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:30:58.863426Z",
     "start_time": "2018-08-12T10:30:58.193672Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('corpus_token_tmp.dat', 'rb') as p:\n",
    "    corpus_tokens_tmp = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:00.010038Z",
     "start_time": "2018-08-12T10:30:58.867296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3825494\n",
      "Vocabulary size = 50003\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_tokens_tmp))\n",
    "vocabulary_size = 50000\n",
    "index_to_word, word_to_index = get_words_mappings(\n",
    "                                        [corpus_tokens_tmp], #cause a list of sentences is expected\n",
    "                                        vocabulary_size)\n",
    "vocabulary_size = len(index_to_word)\n",
    "print(\"Vocabulary size = \" + str(vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:00.180234Z",
     "start_time": "2018-08-12T10:31:00.016220Z"
    }
   },
   "outputs": [],
   "source": [
    "df_word_to_index = pd.DataFrame.from_dict(word_to_index, orient='index')\n",
    "index_to_word_dict = dict([(i,w) for w,i in word_to_index.items()])\n",
    "df_index_to_word = pd.DataFrame.from_dict(index_to_word_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:00.204911Z",
     "start_time": "2018-08-12T10:31:00.184138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "Brigham        24356\n",
      "detour?Sump'n  44129\n",
      "OB             24355\n",
      "Olympico?No    44130\n",
      "yes.'So        44141\n",
      "     0\n",
      "0  EOS\n",
      "1  PAD\n",
      "2    .\n",
      "3    ,\n",
      "4    I\n"
     ]
    }
   ],
   "source": [
    "print(df_word_to_index.head())\n",
    "print(df_index_to_word.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:00.534906Z",
     "start_time": "2018-08-12T10:31:00.209838Z"
    }
   },
   "outputs": [],
   "source": [
    "df_word_to_index.to_csv('w2i.csv', encoding='utf-8')\n",
    "df_index_to_word.to_csv('i2w.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:00.661091Z",
     "start_time": "2018-08-12T10:31:00.537692Z"
    }
   },
   "outputs": [],
   "source": [
    "df_word_to_index = pd.read_csv('w2i.csv', encoding='utf-8', index_col =0)\n",
    "df_index_to_word = pd.read_csv('i2w.csv', encoding='utf-8', index_col =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:03.782527Z",
     "start_time": "2018-08-12T10:31:00.665179Z"
    }
   },
   "outputs": [],
   "source": [
    "word_to_index_dict = df_word_to_index.to_dict(orient='index')\n",
    "index_to_word_dict = df_index_to_word.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:03.796135Z",
     "start_time": "2018-08-12T10:31:03.785969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Brigham': {'0': 24356}, \"detour?Sump'n\": {'0': 44129}, 'OB': {'0': 24355}, 'Olympico?No': {'0': 44130}, \"yes.'So\": {'0': 44141}}\n",
      "{0: {'0': 'EOS'}, 1: {'0': 'PAD'}, 2: {'0': '.'}, 3: {'0': ','}, 4: {'0': 'I'}}\n"
     ]
    }
   ],
   "source": [
    "print({k: word_to_index_dict[k] for k in list(word_to_index_dict)[:5]})\n",
    "print({k: index_to_word_dict[k] for k in list(index_to_word_dict)[:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:08.970642Z",
     "start_time": "2018-08-12T10:31:03.801327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_input (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_emb (Embedding)          (None, 20, 32)       1600096     enc_input[0][0]                  \n",
      "                                                                 dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_lstm (LSTM)                 [(None, 32), (None,  8320        shared_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm (LSTM)                 [(None, 20, 32), (No 8320        shared_emb[1][0]                 \n",
      "                                                                 enc_lstm[0][1]                   \n",
      "                                                                 enc_lstm[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_output (Dense)              (None, 20, 1)        33          dec_lstm[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,616,769\n",
      "Trainable params: 1,616,769\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_model_loaded = load_model('/Users/ashwins/gitlab_repo/chatbot/full_model_r_new_epoch_3.h5')\n",
    "autoencoder_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:08.982577Z",
     "start_time": "2018-08-12T10:31:08.975088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0xb4bcb9898>\n",
      "<keras.engine.input_layer.InputLayer object at 0xb4bcb9908>\n",
      "<keras.layers.embeddings.Embedding object at 0xb4bcb9128>\n",
      "<keras.layers.recurrent.LSTM object at 0xb4bcb9a20>\n",
      "<keras.layers.recurrent.LSTM object at 0xb4bcb9ac8>\n",
      "<keras.layers.core.Dense object at 0xb4beef048>\n"
     ]
    }
   ],
   "source": [
    "for l in autoencoder_model_loaded.layers:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:09.731267Z",
     "start_time": "2018-08-12T10:31:08.987223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.training.Model object at 0xb4fcb70f0>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model = load_model('/Users/ashwins/gitlab_repo/chatbot/enc_model_r_new_epoch_3.h5')\n",
    "print(encoder_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:09.745455Z",
     "start_time": "2018-08-12T10:31:09.736282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "enc_input (InputLayer)       (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "shared_emb (Embedding)       (None, 20, 32)            1600096   \n",
      "_________________________________________________________________\n",
      "enc_lstm (LSTM)              [(None, 32), (None, 32),  8320      \n",
      "=================================================================\n",
      "Total params: 1,608,416\n",
      "Trainable params: 1,608,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = autoencoder_model_loaded.get_layer('enc_input').output\n",
    "# enc_inputs = Input(shape=(None,), name='enc_input')\n",
    "# enc_emb = autoencoder_model_loaded.get_layer('shared_emb').get_output_at(0)\n",
    "enc_lstm = autoencoder_model_loaded.get_layer('enc_lstm').output\n",
    "\n",
    "encoder_model_loaded = Model(enc_inputs, enc_lstm)\n",
    "encoder_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:09.760906Z",
     "start_time": "2018-08-12T10:31:09.751859Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:10.091753Z",
     "start_time": "2018-08-12T10:31:09.766995Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_inp = autoencoder_model_loaded.get_layer('dec_input').output\n",
    "dec_emb = autoencoder_model_loaded.get_layer('shared_emb')(dec_inp)\n",
    "dec_lstm_layer = autoencoder_model_loaded.get_layer('dec_lstm')\n",
    "\n",
    "dec_lstm,  decoder_state_output_h, decoder_state_output_c = dec_lstm_layer(dec_emb, initial_state=decoder_input_states)\n",
    "\n",
    "decoder_output_states = [decoder_state_output_h, decoder_state_output_c]\n",
    "\n",
    "dec_output = autoencoder_model_loaded.get_layer('dec_output')(dec_lstm)\n",
    "\n",
    "decoder_model_loaded = Model([dec_inp] + decoder_input_states , [dec_output] + decoder_output_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:10.104325Z",
     "start_time": "2018-08-12T10:31:10.095353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_input (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_emb (Embedding)          (None, 20, 32)       1600096     dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm (LSTM)                 [(None, 20, 32), (No 8320        shared_emb[2][0]                 \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dec_output (Dense)              (None, 20, 1)        33          dec_lstm[1][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,608,449\n",
      "Trainable params: 1,608,449\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:10.116267Z",
     "start_time": "2018-08-12T10:31:10.110655Z"
    }
   },
   "outputs": [],
   "source": [
    "# index_to_word_dict = dict([(i,w) for w,i in word_to_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:10.128828Z",
     "start_time": "2018-08-12T10:31:10.121217Z"
    }
   },
   "outputs": [],
   "source": [
    "UNKNOWN_TOKEN = \"UNK\"\n",
    "PAD_TOKEN = \"PAD\"\n",
    "EOS_TOKEN = \"EOS\"\n",
    "\n",
    "unknown_token_idx = word_to_index_dict.get(UNKNOWN_TOKEN).get('0')\n",
    "pad_token_idx = word_to_index_dict.get(PAD_TOKEN).get('0')\n",
    "eos_token_idx = word_to_index_dict.get(EOS_TOKEN).get('0')\n",
    "\n",
    "max_sent_len = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode sequence new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:34:17.576018Z",
     "start_time": "2018-08-12T10:34:17.561805Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    op, states_value0, states_value1 = encoder_model_loaded.predict(input_seq)\n",
    "    print(np.array(states_value0).shape, np.array(states_value1).shape)\n",
    "#     states_value0 = np.reshape(np.array(states_value0), (20, -1))\n",
    "#     states_value1 = np.reshape(np.array(states_value1), (20, -1))\n",
    "#     print(states_value0.shape, states_value1.shape)\n",
    "    \n",
    "#     states_value0 = states_value0.tolist()\n",
    "#     states_value1 = states_value1.tolist()\n",
    "#     print(states_value1)\n",
    "    states_value = [states_value0, states_value1]\n",
    "#     states_value = [states_value0, states_value1]\n",
    "#     states_value = [np.argmax(states_value0), np.argmax(states_value1)]\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, max_sent_len))\n",
    "#     target_seq = np.zeros(( max_sent_len, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = word_to_index_dict[\"PAD\"].get('0')\n",
    "    print(target_seq.shape)\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    i=1\n",
    "    while not stop_condition :\n",
    "        output_tokens, h, c = decoder_model_loaded.predict(\n",
    "            [target_seq] + states_value)\n",
    "        print(\"output_tokens shape: \", output_tokens.shape)\n",
    "        print(\"output tokens  : \",output_tokens)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = output_tokens[0, -1, 0]\n",
    "        print(\"max index : \", sampled_token_index)\n",
    "        \n",
    "        print(\"predicted word : \", index_to_word_dict.get(int(sampled_token_index)).get('0'))\n",
    "        sampled_word = index_to_word_dict.get(int(sampled_token_index)).get('0')\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        \n",
    "        if i == max_sent_len-1 or sampled_token_index == unknown_token_idx or sampled_token_index == eos_token_idx:\n",
    "            stop_condition = True\n",
    "            print(\"stpping: \", len(decoded_sentence))\n",
    "\n",
    "        target_seq[0, i] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        print(\"dec state shapes: \", np.array(h).shape, np.array(c).shape)\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode sequence td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:31:10.172332Z",
     "start_time": "2018-08-12T10:31:10.162168Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence_td(input_seq):\n",
    "    print(input_seq.shape)\n",
    "    # Encode the input as state vectors.\n",
    "    op, states_value0, states_value1 = encoder_model_loaded.predict(input_seq)\n",
    "    \n",
    "    print(op.shape)\n",
    "#     print(\"enc op : \", index_to_word_dict.get(np.argmax(op[0,-1,:])).get('0'))\n",
    "    print(np.array(states_value0).shape, np.array(states_value1).shape)\n",
    "#     print(states_value1)\n",
    "    states_value = [states_value0, states_value1]\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.ones((1, max_sent_len))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = word_to_index_dict.get(\"EOS\").get('0')\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "#     while not stop_condition :\n",
    "    output_tokens, h, c = decoder_model_loaded.predict(\n",
    "        [target_seq] + states_value)\n",
    "    print(\"output_tokens shape: \", output_tokens.shape)\n",
    "    print(\"output tokens  : \",output_tokens)\n",
    "    \n",
    "    # Sample a token\n",
    "    for i in range(20):\n",
    "        sampled_token_index = int(output_tokens[0, i, 0])\n",
    "        print(\"predicted word : \", index_to_word_dict.get(sampled_token_index,\"none\").get('0'))\n",
    "#     sampled_word = index_to_word_dict[sampled_token_index]\n",
    "        decoded_sentence += ' ' + index_to_word_dict.get(sampled_token_index,\"none\").get('0')\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#     target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # Update states\n",
    "#     states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:34:27.369678Z",
     "start_time": "2018-08-12T10:34:27.364093Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T10:34:36.832509Z",
     "start_time": "2018-08-12T10:34:36.650334Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Did', ' ', '?']\n",
      "(3,)\n",
      "[227   7  20]\n",
      "[[227   7  20   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "eval data shape (1, 20)\n",
      "(1, 32) (1, 32)\n",
      "(1, 20)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]\n",
      "  [27.518469]]]\n",
      "max index :  27.518469\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.554394]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]\n",
      "  [27.559261]]]\n",
      "max index :  27.559261\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.55992 ]\n",
      "  [27.560009]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]\n",
      "  [27.560019]]]\n",
      "max index :  27.560019\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 1)\n",
      "output tokens  :  [[[27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]\n",
      "  [27.560022]]]\n",
      "max index :  27.560022\n",
      "predicted word :  be\n",
      "stpping:  57\n",
      "dec state shapes:  (1, 32) (1, 32)\n",
      "output is :   be be be be be be be be be be be be be be be be be be be\n"
     ]
    }
   ],
   "source": [
    "test_str = \"Did  ?\" #you change your hair\n",
    "# test_str = \"Hey there?\"\n",
    "# text_eval =\"Did you change your hair?\"\n",
    "eval_data = np.array([word_to_index_dict.get(str(w), word_to_index_dict.get(UNKNOWN_TOKEN).get('0')).get('0') \n",
    "              for w in nlp(test_str)])\n",
    "print([str(w) for w in nlp(test_str)])\n",
    "print(eval_data.shape)\n",
    "print(eval_data)\n",
    "eval_data.resize(max_sent_len)\n",
    "eval_data = np.reshape(eval_data, (-1, max_sent_len))\n",
    "# eval_data = np.reshape(eval_data, (max_sent_len, -1))\n",
    "print(eval_data)\n",
    "print(\"eval data shape\", eval_data.shape)\n",
    "op = decode_sequence(eval_data)\n",
    "\n",
    "print(\"output is : \", op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "123px",
    "width": "162px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
