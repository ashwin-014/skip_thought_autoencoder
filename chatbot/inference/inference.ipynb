{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:35.103885Z",
     "start_time": "2018-08-12T11:04:15.371173Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, TimeDistributed\n",
    "import pickle\n",
    "# import nltk\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "# from keras.utils import preprocessing\n",
    "# from model.textGenModel import TextGenModel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "INPUT_DIR = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:35.532880Z",
     "start_time": "2018-08-12T11:04:35.145881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16841888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Did you change your hair?No.You might wanna think about itI missed you.It says here you exposed yourself to a group of freshmen girls.It was a bratwurst.  I was eating lunch.With the teeth of your zi'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str2=''\n",
    "with open(INPUT_DIR + 'movie_data/movie_conversations_temp.txt', 'r') as f:\n",
    "    corpus_text_2 = f.readlines()\n",
    "#     print(corpus_text_2[0])\n",
    "    for c in corpus_text_2:\n",
    "        str2 = ' '.join([str2, c])\n",
    "\n",
    "print(len(str2))\n",
    "str2[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:36.712385Z",
     "start_time": "2018-08-12T11:04:36.700185Z"
    }
   },
   "outputs": [],
   "source": [
    "# constant token and params for our models\n",
    "START_TOKEN = \"EOS\"\n",
    "END_TOKEN = \"EOS\"\n",
    "UNKNOWN_TOKEN = \"UNK\"\n",
    "PADDING_TOKEN = \"PAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:37.758596Z",
     "start_time": "2018-08-12T11:04:37.746941Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_words_mappings(tokenized_sentences, vocabulary_size):\n",
    "    # Using NLTK\n",
    "    #frequence = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "    #vocab = frequence.most_common(vocabulary_size)\n",
    "\n",
    "    # Using basic counter\n",
    "    counter = collections.Counter(itertools.chain(*tokenized_sentences))\n",
    "    vocab = counter.most_common(vocabulary_size)\n",
    "    index_to_word = [x[0] for x in vocab]\n",
    "    # Add padding for index 0\n",
    "    index_to_word.insert(0, START_TOKEN)\n",
    "    index_to_word.insert(1, PADDING_TOKEN)\n",
    "    # Append unknown token (with index = vocabulary size + 1)\n",
    "    index_to_word.append(UNKNOWN_TOKEN)\n",
    "    word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    "    \n",
    "    return index_to_word, word_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:39.126749Z",
     "start_time": "2018-08-12T11:04:39.096156Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "sent_max_len = 20\n",
    "\n",
    "# hidden_size = 512\n",
    "# hidden_size = 128\n",
    "# embedding_size = 128\n",
    "# batch_size = 64\n",
    "max_sent_len = 20\n",
    "embedding_size = 32\n",
    "stateful = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:40.283832Z",
     "start_time": "2018-08-12T11:04:40.244675Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# corpus_text3 = str2\n",
    "# corpus_tokens_tmp=[]\n",
    "# for i in range(0, 16000000, 100000):\n",
    "#     print(i)\n",
    "#     tmp_corpus = [token.orth_ for token in nlp(corpus_text3[i:i + 100000])]\n",
    "#     corpus_tokens_tmp = corpus_tokens_tmp + tmp_corpus\n",
    "# print('Example tokenized excerpt: {}'.format(corpus_tokens_tmp[10:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:43.097668Z",
     "start_time": "2018-08-12T11:04:41.289714Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('corpus_token_tmp.dat', 'rb') as p:\n",
    "    corpus_tokens_tmp = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:49.474399Z",
     "start_time": "2018-08-12T11:04:46.872068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3825494\n",
      "Vocabulary size = 50003\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_tokens_tmp))\n",
    "vocabulary_size = 50000\n",
    "index_to_word, word_to_index = get_words_mappings(\n",
    "                                        [corpus_tokens_tmp], #cause a list of sentences is expected\n",
    "                                        vocabulary_size)\n",
    "vocabulary_size = len(index_to_word)\n",
    "print(\"Vocabulary size = \" + str(vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:54.003586Z",
     "start_time": "2018-08-12T11:04:53.594885Z"
    }
   },
   "outputs": [],
   "source": [
    "df_word_to_index = pd.DataFrame.from_dict(word_to_index, orient='index')\n",
    "index_to_word_dict = dict([(i,w) for w,i in word_to_index.items()])\n",
    "df_index_to_word = pd.DataFrame.from_dict(index_to_word_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:04:57.684758Z",
     "start_time": "2018-08-12T11:04:57.659133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "rout       30696\n",
      "piloting   37300\n",
      "bite?Sure  44129\n",
      "lawyers     2504\n",
      "SILENCE    24355\n",
      "     0\n",
      "0  EOS\n",
      "1  PAD\n",
      "2    .\n",
      "3    ,\n",
      "4    I\n"
     ]
    }
   ],
   "source": [
    "print(df_word_to_index.head())\n",
    "print(df_index_to_word.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:05:02.175573Z",
     "start_time": "2018-08-12T11:05:01.422376Z"
    }
   },
   "outputs": [],
   "source": [
    "df_word_to_index.to_csv('w2i.csv', encoding='utf-8')\n",
    "df_index_to_word.to_csv('i2w.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:05:06.255396Z",
     "start_time": "2018-08-12T11:05:06.031473Z"
    }
   },
   "outputs": [],
   "source": [
    "df_word_to_index = pd.read_csv('w2i.csv', encoding='utf-8', index_col =0)\n",
    "df_index_to_word = pd.read_csv('i2w.csv', encoding='utf-8', index_col =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:05:19.673973Z",
     "start_time": "2018-08-12T11:05:10.683121Z"
    }
   },
   "outputs": [],
   "source": [
    "word_to_index_dict = df_word_to_index.to_dict(orient='index')\n",
    "index_to_word_dict = df_index_to_word.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:05:24.330205Z",
     "start_time": "2018-08-12T11:05:24.306133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rout': {'0': 30696}, 'piloting': {'0': 37300}, 'bite?Sure': {'0': 44129}, 'SILENCE': {'0': 24355}, 'tricorders': {'0': 44130}}\n",
      "{0: {'0': 'EOS'}, 1: {'0': 'PAD'}, 2: {'0': '.'}, 3: {'0': ','}, 4: {'0': 'I'}}\n"
     ]
    }
   ],
   "source": [
    "print({k: word_to_index_dict[k] for k in list(word_to_index_dict)[:5]})\n",
    "print({k: index_to_word_dict[k] for k in list(index_to_word_dict)[:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:13:22.995881Z",
     "start_time": "2018-08-12T11:13:15.164646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_input (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_input (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_emb (Embedding)          (None, 20, 32)       1600096     enc_input[0][0]                  \n",
      "                                                                 dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_lstm (LSTM)                 [(None, 32), (None,  8320        shared_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm (LSTM)                 [(None, 20, 32), (No 8320        shared_emb[1][0]                 \n",
      "                                                                 enc_lstm[0][1]                   \n",
      "                                                                 enc_lstm[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 20, 50003)    1650099     dec_lstm[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,266,835\n",
      "Trainable params: 3,266,835\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_model_loaded = load_model('/Users/ashwins/gitlab_repo/chatbot/full_model_td_new_epoch_3.h5')\n",
    "autoencoder_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:13:25.318429Z",
     "start_time": "2018-08-12T11:13:25.309946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0xb3a936630>\n",
      "<keras.engine.input_layer.InputLayer object at 0xb3a9366a0>\n",
      "<keras.layers.embeddings.Embedding object at 0xb3a936748>\n",
      "<keras.layers.recurrent.LSTM object at 0xb3a936710>\n",
      "<keras.layers.recurrent.LSTM object at 0xb3a9367b8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0xb3a936518>\n"
     ]
    }
   ],
   "source": [
    "for l in autoencoder_model_loaded.layers:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:13:28.548863Z",
     "start_time": "2018-08-12T11:13:27.549679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.training.Model object at 0xb3a938da0>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model = load_model('/Users/ashwins/gitlab_repo/chatbot/enc_model_td_new_epoch_3.h5')\n",
    "print(encoder_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:13:30.835476Z",
     "start_time": "2018-08-12T11:13:30.821533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "enc_input (InputLayer)       (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "shared_emb (Embedding)       (None, 20, 32)            1600096   \n",
      "_________________________________________________________________\n",
      "enc_lstm (LSTM)              [(None, 32), (None, 32),  8320      \n",
      "=================================================================\n",
      "Total params: 1,608,416\n",
      "Trainable params: 1,608,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = autoencoder_model_loaded.get_layer('enc_input').output\n",
    "# enc_inputs = Input(shape=(None,), name='enc_input')\n",
    "# enc_emb = autoencoder_model_loaded.get_layer('shared_emb').get_output_at(0)\n",
    "enc_lstm = autoencoder_model_loaded.get_layer('enc_lstm').output\n",
    "\n",
    "encoder_model_loaded = Model(enc_inputs, enc_lstm)\n",
    "encoder_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:13:33.396293Z",
     "start_time": "2018-08-12T11:13:33.389488Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:16:28.682714Z",
     "start_time": "2018-08-12T11:16:28.307115Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_inp = autoencoder_model_loaded.get_layer('dec_input').output\n",
    "dec_emb = autoencoder_model_loaded.get_layer('shared_emb')(dec_inp)\n",
    "dec_lstm_layer = autoencoder_model_loaded.get_layer('dec_lstm')\n",
    "\n",
    "dec_lstm,  decoder_state_output_h, decoder_state_output_c = dec_lstm_layer(dec_emb, initial_state=decoder_input_states)\n",
    "\n",
    "decoder_output_states = [decoder_state_output_h, decoder_state_output_c]\n",
    "\n",
    "dec_output = autoencoder_model_loaded.get_layer('time_distributed_2')(dec_lstm)\n",
    "\n",
    "decoder_model_loaded = Model([dec_inp] + decoder_input_states , [dec_output] + decoder_output_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:16:30.506209Z",
     "start_time": "2018-08-12T11:16:30.486616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_input (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_emb (Embedding)          (None, 20, 32)       1600096     dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm (LSTM)                 [(None, 20, 32), (No 8320        shared_emb[5][0]                 \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 20, 50003)    1650099     dec_lstm[3][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,258,515\n",
      "Trainable params: 3,258,515\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:16:34.255052Z",
     "start_time": "2018-08-12T11:16:34.251269Z"
    }
   },
   "outputs": [],
   "source": [
    "# index_to_word_dict = dict([(i,w) for w,i in word_to_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:16:36.007357Z",
     "start_time": "2018-08-12T11:16:35.998254Z"
    }
   },
   "outputs": [],
   "source": [
    "UNKNOWN_TOKEN = \"UNK\"\n",
    "PAD_TOKEN = \"PAD\"\n",
    "EOS_TOKEN = \"EOS\"\n",
    "\n",
    "unknown_token_idx = word_to_index_dict.get(UNKNOWN_TOKEN).get('0')\n",
    "pad_token_idx = word_to_index_dict.get(PAD_TOKEN).get('0')\n",
    "eos_token_idx = word_to_index_dict.get(EOS_TOKEN).get('0')\n",
    "\n",
    "max_sent_len = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode sequence new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:16:41.236071Z",
     "start_time": "2018-08-12T11:16:41.222934Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    op, states_value0, states_value1 = encoder_model_loaded.predict(input_seq)\n",
    "    print(np.array(states_value0).shape, np.array(states_value1).shape)\n",
    "#     states_value0 = np.reshape(np.array(states_value0), (20, -1))\n",
    "#     states_value1 = np.reshape(np.array(states_value1), (20, -1))\n",
    "#     print(states_value0.shape, states_value1.shape)\n",
    "    \n",
    "#     states_value0 = states_value0.tolist()\n",
    "#     states_value1 = states_value1.tolist()\n",
    "#     print(states_value1)\n",
    "    states_value = [states_value0, states_value1]\n",
    "#     states_value = [states_value0, states_value1]\n",
    "#     states_value = [np.argmax(states_value0), np.argmax(states_value1)]\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, max_sent_len))\n",
    "#     target_seq = np.zeros(( max_sent_len, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = word_to_index_dict[\"PAD\"].get('0')\n",
    "    print(target_seq.shape)\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    i=1\n",
    "    while not stop_condition :\n",
    "        output_tokens, h, c = decoder_model_loaded.predict(\n",
    "            [target_seq] + states_value)\n",
    "        print(\"output_tokens shape: \", output_tokens.shape)\n",
    "        print(\"output tokens  : \",output_tokens)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        print(\"max index : \", sampled_token_index)\n",
    "        \n",
    "        print(\"predicted word : \", index_to_word_dict.get(sampled_token_index).get('0'))\n",
    "        sampled_word = index_to_word_dict.get(sampled_token_index).get('0')\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        \n",
    "        if i == max_sent_len-1 or sampled_token_index == unknown_token_idx or sampled_token_index == eos_token_idx:\n",
    "            stop_condition = True\n",
    "#             print(\"stpping: \", len(decoded_sentence))\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "#         target_seq.append(sampled_token_index )\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "#         target_seq = np.zeros((1, max_sent_len))\n",
    "        target_seq[0, i] = sampled_token_index\n",
    "#         target_seq[i, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        print(\"dec state shapes: \", np.array(h).shape, np.array(c).shape)\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode sequence td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:18:03.648698Z",
     "start_time": "2018-08-12T11:18:03.637911Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence_td(input_seq):\n",
    "    print(input_seq.shape)\n",
    "    # Encode the input as state vectors.\n",
    "    op, states_value0, states_value1 = encoder_model_loaded.predict(input_seq)\n",
    "    \n",
    "    print(op.shape)\n",
    "#     print(\"enc op : \", index_to_word_dict.get(np.argmax(op[0,-1,:])).get('0'))\n",
    "    print(np.array(states_value0).shape, np.array(states_value1).shape)\n",
    "#     print(states_value1)\n",
    "    states_value = [states_value0, states_value1]\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.ones((1, max_sent_len))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = word_to_index_dict.get(\"EOS\").get('0')\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "#     while not stop_condition :\n",
    "    output_tokens, h, c = decoder_model_loaded.predict(\n",
    "        [target_seq] + states_value)\n",
    "    print(\"output_tokens shape: \", output_tokens.shape)\n",
    "    print(\"output tokens  : \",output_tokens)\n",
    "    \n",
    "    # Sample a token\n",
    "    for i in range(20):\n",
    "        sampled_token_index = np.argmax(output_tokens[0, i, :])\n",
    "        print(\"predicted word : \", index_to_word_dict.get(sampled_token_index,\"none\").get('0'))\n",
    "#     sampled_word = index_to_word_dict[sampled_token_index]\n",
    "        decoded_sentence += ' ' + index_to_word_dict.get(sampled_token_index,\"none\").get('0')\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#     target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # Update states\n",
    "#     states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:17:02.148517Z",
     "start_time": "2018-08-12T11:17:02.144550Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T11:18:46.305243Z",
     "start_time": "2018-08-12T11:18:46.107880Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Did', 'you', 'change', 'your', 'hair', '?']\n",
      "(6,)\n",
      "[227   5 497  28 740  20]\n",
      "[[227   5 497  28 740  20   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "eval data shape (1, 20)\n",
      "(1, 20)\n",
      "(1, 32)\n",
      "(1, 32) (1, 32)\n",
      "output_tokens shape:  (1, 20, 50003)\n",
      "output tokens  :  [[[1.3479628e-06 1.3167072e-06 1.3173703e-06 ... 1.2825701e-06\n",
      "   1.2652702e-06 1.3589142e-02]\n",
      "  [1.3066389e-06 1.2751137e-06 1.2758193e-06 ... 1.2428253e-06\n",
      "   1.2261339e-06 1.3759612e-02]\n",
      "  [1.3062262e-06 1.2747087e-06 1.2754151e-06 ... 1.2424281e-06\n",
      "   1.2257420e-06 1.3761158e-02]\n",
      "  ...\n",
      "  [1.3061598e-06 1.2746426e-06 1.2753503e-06 ... 1.2423649e-06\n",
      "   1.2256785e-06 1.3761417e-02]\n",
      "  [1.3061598e-06 1.2746426e-06 1.2753503e-06 ... 1.2423649e-06\n",
      "   1.2256785e-06 1.3761417e-02]\n",
      "  [1.3061598e-06 1.2746426e-06 1.2753503e-06 ... 1.2423649e-06\n",
      "   1.2256785e-06 1.3761417e-02]]]\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "predicted word :  I\n",
      "output is :   I I I I I I I I I I I I I I I I I I I I\n"
     ]
    }
   ],
   "source": [
    "test_str = \"Did you change your hair?\" #you change your hair\n",
    "# test_str = \"Hey there?\"\n",
    "# text_eval =\"Did you change your hair?\"\n",
    "eval_data = np.array([word_to_index_dict.get(str(w), word_to_index_dict.get(UNKNOWN_TOKEN).get('0')).get('0') \n",
    "              for w in nlp(test_str)])\n",
    "print([str(w) for w in nlp(test_str)])\n",
    "print(eval_data.shape)\n",
    "print(eval_data)\n",
    "eval_data.resize(max_sent_len)\n",
    "eval_data = np.reshape(eval_data, (-1, max_sent_len))\n",
    "# eval_data = np.reshape(eval_data, (max_sent_len, -1))\n",
    "print(eval_data)\n",
    "print(\"eval data shape\", eval_data.shape)\n",
    "op = decode_sequence_td(eval_data)\n",
    "\n",
    "print(\"output is : \", op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "123px",
    "width": "162px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
