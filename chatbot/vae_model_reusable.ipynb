{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:32:17.428192Z",
     "start_time": "2018-08-08T04:32:15.994433Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "\n",
    "INPUT_DIR = \"/Users/ashwins/Scripts/chatbot/\"\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, TimeDistributed\n",
    "import pickle\n",
    "# import nltk\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "# from keras.utils import preprocessing\n",
    "# from model.textGenModel import TextGenModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:32:21.474752Z",
     "start_time": "2018-08-08T04:32:21.456984Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, RepeatVector, Bidirectional, Dropout\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:32:24.895600Z",
     "start_time": "2018-08-08T04:32:24.890305Z"
    }
   },
   "outputs": [],
   "source": [
    "# constant token and params for our models\n",
    "START_TOKEN = \"EOS\"\n",
    "END_TOKEN = \"EOS\"\n",
    "UNKNOWN_TOKEN = \"UNK\"\n",
    "PADDING_TOKEN = \"PAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:32:26.902063Z",
     "start_time": "2018-08-08T04:32:26.896688Z"
    }
   },
   "outputs": [],
   "source": [
    "# vocabulary_size = 22285\n",
    "sent_max_len = 20\n",
    "\n",
    "# hidden_size = 512\n",
    "hidden_size = 128\n",
    "embedding_size = 128\n",
    "batch_size = 64\n",
    "stateful = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:51:49.342250Z",
     "start_time": "2018-08-08T04:51:44.684376Z"
    }
   },
   "outputs": [],
   "source": [
    "import load_train_data\n",
    "import load_vae_model\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T05:25:15.966050Z",
     "start_time": "2018-08-08T05:23:51.294919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "df_lines :                                                   dialogue     l_no\n",
      "0                                            They do not!    L1045\n",
      "1                                             They do to!    L1044\n",
      "2                                              I hope so.     L985\n",
      "3                                               She okay?     L984\n",
      "4                                               Let's go.     L925\n",
      "5                                                     Wow     L924\n",
      "6          Okay -- you're gonna need to learn how to lie.     L872\n",
      "7                                                      No     L871\n",
      "8       I'm kidding.  You know how sometimes you just ...     L870\n",
      "9                        Like my fear of wearing pastels?     L869\n",
      "10                                        The \"real you\".     L868\n",
      "11                                       What good stuff?     L867\n",
      "12      I figured you'd get to the good stuff eventually.     L866\n",
      "13      Thank God!  If I had to hear one more story ab...     L865\n",
      "14      Me.  This endless ...blonde babble. I'm like, ...     L864\n",
      "15                                             What crap?     L863\n",
      "16                            do you listen to this crap?     L862\n",
      "17                                                  No...     L861\n",
      "18      Then Guillermo says, \"If you go any lighter, y...     L860\n",
      "19                          You always been this selfish?     L699\n",
      "20                                                    But     L698\n",
      "21                        Then that's all you had to say.     L697\n",
      "22                                            Well, no...     L696\n",
      "23          You never wanted to go out with 'me, did you?     L695\n",
      "24                                                 I was?     L694\n",
      "25      I looked for you back at the party, but you al...     L693\n",
      "26                                                   Tons     L663\n",
      "27                                      Have fun tonight?     L662\n",
      "28                   I believe we share an art instructor     L578\n",
      "29                                     You know Chastity?     L577\n",
      "...                                                   ...      ...\n",
      "304683  The only reports of enemy activity have come f...  L666460\n",
      "304684      Our runners bare his dispatches, do they not?  L666385\n",
      "304685  Er, called Noggs, Sir Actual name is Norris-Ne...  L666384\n",
      "304686  What's that strange name the newspaper chap's ...  L666383\n",
      "304687               But will they make good use of them?  L666252\n",
      "304688  Yes. I see you've issued each of them with a M...  L666251\n",
      "304689                  Right.  Bombardier, to me please.  L666502\n",
      "304690  Well, fed or hungry, Pulleine wants them in po...  L666501\n",
      "304691  Well, my horses are feeding, as you may observ...  L666500\n",
      "304692   How quickly can you move your artillery forward?  L666499\n",
      "304693                                               Yes.  L666498\n",
      "304694                                            Stuart?  L666497\n",
      "304695  Keep steady. You're the best shots of the Twen...  L666576\n",
      "304696  Choose your targets men. That's right Watch th...  L666575\n",
      "304697  ft could be you flatter yourself CoghilL It's ...  L666327\n",
      "304698    Well that one. The one who keeps looking at me.  L666326\n",
      "304699                                         Which one?  L666325\n",
      "304700  Do you think she might be interested in  someone?  L666324\n",
      "304701  Well that's typical of Her Majesty's army. App...  L666264\n",
      "304702  Um. There are rumours that my Lord Chelmsford ...  L666263\n",
      "304703  Lighting COGHILL' 5 cigar: Our good Colonel Du...  L666262\n",
      "304704  So far only their scouts. But we have had repo...  L666522\n",
      "304705  And I assure you, you do not In fact I'd be ob...  L666521\n",
      "304706  Well I assure you, Sir, I have no desire to cr...  L666520\n",
      "304707  I think Chelmsford wants a good man on the bor...  L666372\n",
      "304708  Lord Chelmsford seems to want me to stay back ...  L666371\n",
      "304709  I'm to take the Sikali with the main column to...  L666370\n",
      "304710                           Your orders, Mr Vereker?  L666369\n",
      "304711  Good ones, yes, Mr Vereker. Gentlemen who can ...  L666257\n",
      "304712  Colonel Durnford... William Vereker. I hear yo...  L666256\n",
      "\n",
      "[304713 rows x 2 columns]\n",
      "\n",
      "\n",
      "df_convos :             end    start\n",
      "0         L199     L198\n",
      "1         L208     L207\n",
      "2         L277     L276\n",
      "3         L281     L280\n",
      "4         L364     L363\n",
      "5         L366     L365\n",
      "6         L368     L367\n",
      "7         L576     L575\n",
      "8         L578     L577\n",
      "9         L663     L662\n",
      "10        L861     L860\n",
      "11        L925     L924\n",
      "12        L985     L984\n",
      "13       L1045    L1044\n",
      "14        L580     L579\n",
      "15        L660     L659\n",
      "16        L953     L952\n",
      "17        L395     L394\n",
      "18        L397     L396\n",
      "19        L593     L592\n",
      "20        L760     L759\n",
      "21        L165     L164\n",
      "22        L320     L319\n",
      "23        L530     L529\n",
      "24        L543     L542\n",
      "25        L602     L601\n",
      "26        L656     L655\n",
      "27        L983     L982\n",
      "28       L1022    L1021\n",
      "29       L1052    L1051\n",
      "...        ...      ...\n",
      "38061  L665841  L665840\n",
      "38062  L665862  L665861\n",
      "38063  L665874  L665873\n",
      "38064  L665905  L665904\n",
      "38065  L665958  L665957\n",
      "38066  L666030  L666029\n",
      "38067  L666042  L666041\n",
      "38068  L666211  L666210\n",
      "38069  L666215  L666214\n",
      "38070  L666222  L666221\n",
      "38071  L665652  L665651\n",
      "38072  L665886  L665885\n",
      "38073  L665901  L665900\n",
      "38074  L666150  L666149\n",
      "38075  L666159  L666158\n",
      "38076  L666161  L666160\n",
      "38077  L666167  L666166\n",
      "38078  L666169  L666168\n",
      "38079  L665993  L665992\n",
      "38080  L666463  L666462\n",
      "38081  L666250  L666249\n",
      "38082  L666358  L666357\n",
      "38083  L666484  L666483\n",
      "38084  L666488  L666487\n",
      "38085  L666252  L666251\n",
      "38086  L666461  L666460\n",
      "38087  L666486  L666485\n",
      "38088  L666547  L666546\n",
      "38089  L666576  L666575\n",
      "38090  L666257  L666256\n",
      "\n",
      "[38091 rows x 2 columns]\n",
      "16841888\n",
      "Example tokenized excerpt: ['think', 'about', 'itI', 'missed', 'you', '.', 'It', 'says', 'here', 'you']\n",
      "3825494\n",
      "Vocabulary size = 50003\n",
      "                                            dialogue  l_no  l_no_int   end  \\\n",
      "0                                  That I'm used to.   L77        77   L78   \n",
      "1                                       Tempestuous?  L108       108  L109   \n",
      "2  Mandella, eat.  Starving yourself is a very sl...  L129       129  L130   \n",
      "3                                       What's this?  L131       131  L132   \n",
      "4  I realize that the men of this fine institutio...  L133       133  L134   \n",
      "\n",
      "  start  \n",
      "0   L77  \n",
      "1  L108  \n",
      "2  L129  \n",
      "3  L131  \n",
      "4  L133  \n",
      "                                          dialogue_x l_no_x  l_no_int_x   end  \\\n",
      "0                                  That I'm used to.    L77          77   L78   \n",
      "1                                       Tempestuous?   L108         108  L109   \n",
      "2  Mandella, eat.  Starving yourself is a very sl...   L129         129  L130   \n",
      "3                                       What's this?   L131         131  L132   \n",
      "4  I realize that the men of this fine institutio...   L133         133  L134   \n",
      "\n",
      "  start                                         dialogue_y l_no_y  l_no_int_y  \n",
      "0   L77  Yeah, but these guys have never seen a horse. ...    L78          78  \n",
      "1  L108  No ... I believe \"heinous bitch\" is the term u...   L109         109  \n",
      "2  L129                                     Just a little.   L130         130  \n",
      "3  L131                                 An attempted slit.   L132         132  \n",
      "4  L133        But imagine the things he'd say during sex.   L134         134  \n",
      "(38091, 4)\n",
      "\n",
      "\n",
      "df_train_inputs.shape :  (38091, 4)\n",
      "\n",
      "\n",
      "df_train_inputs.head() :      end                                              input  \\\n",
      "0   L78                              [70, 4, 2071, 318, 8]   \n",
      "1  L109                                            [50002]   \n",
      "2  L130  [50002, 511, 37061, 263, 21, 9, 154, 1182, 118...   \n",
      "3  L132                                     [42, 2681, 29]   \n",
      "4  L134  [4, 907, 17, 6, 345, 14, 29, 319, 4662, 43, 15...   \n",
      "\n",
      "                                              output start  \n",
      "0  [157, 66, 207, 306, 24, 114, 305, 9, 1155, 115...   L77  \n",
      "1  [89, 4, 204, 20355, 732, 21, 6, 2877, 318, 375...  L108  \n",
      "2                                      [197, 9, 126]  L129  \n",
      "3                                  [749, 8205, 7050]  L131  \n",
      "4        [79, 959, 6, 185, 39, 3627, 110, 1309, 710]  L133  \n",
      "\n",
      "\n",
      "encoder_input_data.shape :  (38080, 20)\n",
      "\n",
      "\n",
      "encoder_input_data[:5] :  [[   70     4  2071   318     8     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [50002     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [50002   511 37061   263    21     9   154  1182   118     8   413     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   42  2681    29     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    4   907    17     6   345    14    29   319  4662    43 15293  8799\n",
      "     66   927   263    72     5    59    27    36]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "decoder_input_data.shape :  (38080, 20)\n",
      "\n",
      "\n",
      "decoder_input_data[:5] :  [[  157    66   207   306    24   114   305     9  1155   115    48  5237\n",
      "    142     8 17591 20930     0     0     0     0]\n",
      " [   89     4   204 20355   732    21     6  2877   318   375  1399     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [  197     9   126     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [  749  8205  7050     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   79   959     6   185    39  3627   110  1309   710     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n",
      "\n",
      "\n",
      "length :  503\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4855829def32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_train_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gitlab_repo/chatbot/load_train_data.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mdecoder_target_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m38080\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmax_sent_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;31m# decoder_target_data = np.expand_dims(decoder_target_data, -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mdecoder_target_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m38080\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\ndecoder_target_data.shape : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(load_train_data)\n",
    "encoder_input_data, decoder_input_data, decoder_target_data = load_train_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T05:25:15.980878Z",
     "start_time": "2018-08-08T05:23:55.819Z"
    }
   },
   "outputs": [],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_target_data.shape)\n",
    "print(encoder_input_data[:1])\n",
    "print(decoder_input_data[:1])\n",
    "print(decoder_target_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T05:13:01.011058Z",
     "start_time": "2018-08-08T05:12:59.136376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_input (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_emb (Embedding)          (None, 20, 64)       32000192    enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enc_lstm (LSTM)                 (None, 64)           33024       shared_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           enc_lstm[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2080        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           2080        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 32)           0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_7 (RepeatVector)  (None, 20, 32)       0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm_h (LSTM)               (None, 20, 64)       24832       repeat_vector_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm_mean (LSTM)            (None, 20, 20)       6800        dec_lstm_h[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 32,069,008\n",
      "Trainable params: 32,069,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "enc_input (InputLayer)       (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "shared_emb (Embedding)       (None, 20, 64)            32000192  \n",
      "_________________________________________________________________\n",
      "enc_lstm (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 32,035,296\n",
      "Trainable params: 32,035,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_8 (RepeatVecto (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "dec_lstm_h (LSTM)            (None, 20, 64)            24832     \n",
      "_________________________________________________________________\n",
      "dec_lstm_mean (LSTM)         (None, 20, 20)            6800      \n",
      "=================================================================\n",
      "Total params: 31,632\n",
      "Trainable params: 31,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(load_vae_model)\n",
    "vae, encoder, generator = load_vae_model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T05:05:30.004235Z",
     "start_time": "2018-08-08T05:05:12.584532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [64,20] vs. [64]\n\t [[Node: training/Adam/gradients/loss/dec_lstm_mean_loss/add_1_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@training/Adam/gradients/loss/dec_lstm_mean_loss/add_1_grad/Reshape_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/Adam/gradients/loss/dec_lstm_mean_loss/add_1_grad/Shape, training/Adam/gradients/loss/dec_lstm_mean_loss/add_1_grad/Shape_1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-36e8754decb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         validation_data=(encoder_input_data[5000:6000], decoder_target_data[5000:6000] ))\n\u001b[0m",
      "\u001b[0;32m/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[0;32m-> 1454\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Anaconda3/anaconda3/envs/env1/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [64,20] vs. [64]\n\t [[Node: training/Adam/gradients/loss/dec_lstm_mean_loss/add_1_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@training/Adam/gradients/loss/dec_lstm_mean_loss/add_1_grad/Reshape_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/Adam/gradients/loss/dec_lstm_mean_loss/add_1_grad/Shape, training/Adam/gradients/loss/dec_lstm_mean_loss/add_1_grad/Shape_1)]]"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "batch_size_size = 96\n",
    "vae.fit(encoder_input_data[:5000], decoder_target_data[:5000] ,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(encoder_input_data[5000:6000], decoder_target_data[5000:6000] ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
